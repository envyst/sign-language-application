{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine learning model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wATOz2xOuR1"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shby2e9gOxuf",
        "outputId": "18889adf-99e5-4639-d5f1-aacfce1a020c"
      },
      "source": [
        "#Kode buat ngebaca dataset\n",
        "def get_data(filename):\n",
        " \n",
        "    with open(filename) as training_file:\n",
        "        csv_file = csv.reader(training_file, delimiter = ',')\n",
        "        first_row = True\n",
        "        str_labels = []\n",
        "        str_images = []\n",
        "        \n",
        "        for row in csv_file:\n",
        "            if first_row:\n",
        "                first_row = False\n",
        "            else:\n",
        "                str_labels.append(row[0])\n",
        "                images_data = np.array_split(row[1:],28)\n",
        "                str_images.append(images_data)\n",
        "\n",
        "                \n",
        "        labels = np.array(str_labels).astype('float')\n",
        "        images = np.array(str_images).astype('float')\n",
        "                \n",
        "        \n",
        "    return images, labels\n",
        "\n",
        "path_sign_mnist_train = f\"./sign_mnist_train.csv\"\n",
        "path_sign_mnist_validation = f\"./sign_mnist_validation.csv\"\n",
        "training_images, training_labels = get_data(path_sign_mnist_train)\n",
        "validation_images, validation_labels = get_data(path_sign_mnist_validation)\n",
        "\n",
        "#buat ngecek aja\n",
        "print(training_images.shape)\n",
        "print(training_labels.shape)\n",
        "print(validation_images.shape)\n",
        "print(validation_labels.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27455, 28, 28)\n",
            "(27455,)\n",
            "(7172, 28, 28)\n",
            "(7172,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjUffrcwPAfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7865a387-0ce5-4041-d24e-23bf5aebb091"
      },
      "source": [
        "#Kode buat ngedefinisiin data buat training sama testing dari model\n",
        "training_images = np.expand_dims(training_images, axis = 3)\n",
        "validation_images = np.expand_dims(validation_images, axis = 3)\n",
        "\n",
        "training_images_datagen = ImageDataGenerator(\n",
        "        rescale = 1./255,       # Nilai pixel adalah antara 0 - 255, dengan menggunakan fungsi rescale=1/255 maka datanya menjadi antara 0 - 1\n",
        "\t      rotation_range=30,      # Besar rentang derajat untuk rotasi acak\n",
        "        width_shift_range=0.2,  # Rentang nilai untuk pergeseran horizontal acak \n",
        "        height_shift_range=0.2, # Rentang nilai untuk satu pergeseran vertikal acak\n",
        "        shear_range=0.2,        # Sudut geser pada arah berlawanan jarum jam (radian)\n",
        "        zoom_range=0.2,         # Rentang nilai untuk pembesaran secara acah\n",
        "        horizontal_flip=True,   #Gambarnya akan diflip secara horizontal\n",
        "        fill_mode='nearest')    #Titik di luar batas input diisi sesuai dengan mode yang diberikan\n",
        "\n",
        "#Selanjutnya kita lakukan untuk data validation\n",
        "validation_images_datagen = ImageDataGenerator(\n",
        "        rescale = 1./255,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "print(training_images.shape)\n",
        "print(validation_images.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27455, 28, 28, 1)\n",
            "(7172, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTfMLe9bPJU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd839ac9-64e3-44bd-d122-1a8f79f62afb"
      },
      "source": [
        "#Kode buat ngedefinisiin modelnya, kompilasinya (training) sama testing hasil training modelnya\n",
        "# membuat model sequential\n",
        "model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape= (28,28,1)), #Kita konvolusi menjadi 64 bagian berukuran 3x3\n",
        "      tf.keras.layers.MaxPooling2D(2,2),                     # Dengan filter 2x2, kita ambil nilai maximum pada tiap area pergeseran filter\n",
        "      tf.keras.layers.Conv2D(128,(3,3), activation= 'relu'), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),                     \n",
        "      tf.keras.layers.Conv2D(256,(3,3), activation= 'relu'), \n",
        "      tf.keras.layers.MaxPooling2D(2,2),                    \n",
        "      tf.keras.layers.Dropout(0.2),                          # Mencegah overfitting                      \n",
        "      tf.keras.layers.Flatten(),                             # Untuk membuat semua matriks menjadi berukuran single vektor dan menjadi input bagi layer berikutnya\n",
        "      tf.keras.layers.Dense(512, activation= tf.nn.relu),   \n",
        "      tf.keras.layers.Dense(26, activation= tf.nn.softmax)]) # Angka 26 menunjukkan jumlah kelas\n",
        "                                                             # Kita menggunakan softmax karena dapat melakukan prediksi untuk multiclass      \n",
        "\n",
        "                                                          \n",
        "\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy') > 0.96):            # Threshold accuracy saya buat 0.96, karena awalnya masih salah prediksi\n",
        "        print(\"\\nAkurasi tercapai\")\n",
        "        self.model.stop_training = True\n",
        "callbacks = myCallback() \n",
        "\n",
        "\n",
        "history = model.fit_generator(training_images_datagen.flow(training_images, training_labels),\n",
        "          epochs = 1000,\n",
        "          validation_data=validation_images_datagen.flow(validation_images, validation_labels),\n",
        "          callbacks=[callbacks])\n",
        "\n",
        "model.evaluate(validation_images, validation_labels, verbose=0)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 2.6141 - accuracy: 0.1855 - val_loss: 1.9288 - val_accuracy: 0.3614\n",
            "Epoch 2/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 1.6600 - accuracy: 0.4538 - val_loss: 1.3951 - val_accuracy: 0.5456\n",
            "Epoch 3/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 1.2624 - accuracy: 0.5782 - val_loss: 1.1016 - val_accuracy: 0.6347\n",
            "Epoch 4/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 1.0515 - accuracy: 0.6482 - val_loss: 0.9020 - val_accuracy: 0.6887\n",
            "Epoch 5/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.9091 - accuracy: 0.6902 - val_loss: 0.7828 - val_accuracy: 0.7342\n",
            "Epoch 6/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.8185 - accuracy: 0.7233 - val_loss: 0.7232 - val_accuracy: 0.7549\n",
            "Epoch 7/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.7408 - accuracy: 0.7479 - val_loss: 0.6965 - val_accuracy: 0.7681\n",
            "Epoch 8/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.6772 - accuracy: 0.7675 - val_loss: 0.5747 - val_accuracy: 0.8008\n",
            "Epoch 9/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.6361 - accuracy: 0.7810 - val_loss: 0.5704 - val_accuracy: 0.8076\n",
            "Epoch 10/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.5889 - accuracy: 0.7974 - val_loss: 0.5673 - val_accuracy: 0.8095\n",
            "Epoch 11/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.5585 - accuracy: 0.8097 - val_loss: 0.4916 - val_accuracy: 0.8320\n",
            "Epoch 12/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.5325 - accuracy: 0.8203 - val_loss: 0.4462 - val_accuracy: 0.8422\n",
            "Epoch 13/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.5091 - accuracy: 0.8285 - val_loss: 0.4613 - val_accuracy: 0.8419\n",
            "Epoch 14/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.4999 - accuracy: 0.8289 - val_loss: 0.4573 - val_accuracy: 0.8430\n",
            "Epoch 15/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.4739 - accuracy: 0.8394 - val_loss: 0.4078 - val_accuracy: 0.8560\n",
            "Epoch 16/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.4493 - accuracy: 0.8460 - val_loss: 0.4308 - val_accuracy: 0.8532\n",
            "Epoch 17/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.4471 - accuracy: 0.8488 - val_loss: 0.3774 - val_accuracy: 0.8673\n",
            "Epoch 18/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.4270 - accuracy: 0.8548 - val_loss: 0.3809 - val_accuracy: 0.8691\n",
            "Epoch 19/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.4171 - accuracy: 0.8611 - val_loss: 0.3636 - val_accuracy: 0.8737\n",
            "Epoch 20/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.4016 - accuracy: 0.8626 - val_loss: 0.3537 - val_accuracy: 0.8760\n",
            "Epoch 21/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3875 - accuracy: 0.8699 - val_loss: 0.3490 - val_accuracy: 0.8837\n",
            "Epoch 22/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3794 - accuracy: 0.8706 - val_loss: 0.3116 - val_accuracy: 0.8951\n",
            "Epoch 23/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3716 - accuracy: 0.8761 - val_loss: 0.3574 - val_accuracy: 0.8773\n",
            "Epoch 24/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3689 - accuracy: 0.8737 - val_loss: 0.3016 - val_accuracy: 0.8993\n",
            "Epoch 25/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3530 - accuracy: 0.8795 - val_loss: 0.3848 - val_accuracy: 0.8714\n",
            "Epoch 26/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3525 - accuracy: 0.8812 - val_loss: 0.3059 - val_accuracy: 0.8975\n",
            "Epoch 27/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3471 - accuracy: 0.8837 - val_loss: 0.3531 - val_accuracy: 0.8798\n",
            "Epoch 28/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3443 - accuracy: 0.8844 - val_loss: 0.2996 - val_accuracy: 0.8968\n",
            "Epoch 29/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3251 - accuracy: 0.8914 - val_loss: 0.3017 - val_accuracy: 0.8972\n",
            "Epoch 30/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3294 - accuracy: 0.8891 - val_loss: 0.3035 - val_accuracy: 0.8988\n",
            "Epoch 31/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3242 - accuracy: 0.8918 - val_loss: 0.2973 - val_accuracy: 0.9000\n",
            "Epoch 32/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3166 - accuracy: 0.8928 - val_loss: 0.2734 - val_accuracy: 0.9017\n",
            "Epoch 33/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3189 - accuracy: 0.8917 - val_loss: 0.2966 - val_accuracy: 0.8981\n",
            "Epoch 34/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3133 - accuracy: 0.8942 - val_loss: 0.2539 - val_accuracy: 0.9123\n",
            "Epoch 35/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3068 - accuracy: 0.8963 - val_loss: 0.2992 - val_accuracy: 0.8978\n",
            "Epoch 36/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.3095 - accuracy: 0.8949 - val_loss: 0.2549 - val_accuracy: 0.9136\n",
            "Epoch 37/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2980 - accuracy: 0.9007 - val_loss: 0.2547 - val_accuracy: 0.9134\n",
            "Epoch 38/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2871 - accuracy: 0.9033 - val_loss: 0.2536 - val_accuracy: 0.9109\n",
            "Epoch 39/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2969 - accuracy: 0.9004 - val_loss: 0.2640 - val_accuracy: 0.9094\n",
            "Epoch 40/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2873 - accuracy: 0.9052 - val_loss: 0.2768 - val_accuracy: 0.9055\n",
            "Epoch 41/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2895 - accuracy: 0.9034 - val_loss: 0.2812 - val_accuracy: 0.9010\n",
            "Epoch 42/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2987 - accuracy: 0.9021 - val_loss: 0.2397 - val_accuracy: 0.9175\n",
            "Epoch 43/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2774 - accuracy: 0.9058 - val_loss: 0.3222 - val_accuracy: 0.8961\n",
            "Epoch 44/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2835 - accuracy: 0.9058 - val_loss: 0.2643 - val_accuracy: 0.9119\n",
            "Epoch 45/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2745 - accuracy: 0.9078 - val_loss: 0.2648 - val_accuracy: 0.9102\n",
            "Epoch 46/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2718 - accuracy: 0.9070 - val_loss: 0.2622 - val_accuracy: 0.9138\n",
            "Epoch 47/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2668 - accuracy: 0.9099 - val_loss: 0.2202 - val_accuracy: 0.9255\n",
            "Epoch 48/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2745 - accuracy: 0.9075 - val_loss: 0.2588 - val_accuracy: 0.9140\n",
            "Epoch 49/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2728 - accuracy: 0.9105 - val_loss: 0.2455 - val_accuracy: 0.9183\n",
            "Epoch 50/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2709 - accuracy: 0.9069 - val_loss: 0.2669 - val_accuracy: 0.9102\n",
            "Epoch 51/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2676 - accuracy: 0.9122 - val_loss: 0.2645 - val_accuracy: 0.9092\n",
            "Epoch 52/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2610 - accuracy: 0.9140 - val_loss: 0.2338 - val_accuracy: 0.9198\n",
            "Epoch 53/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2563 - accuracy: 0.9155 - val_loss: 0.2577 - val_accuracy: 0.9120\n",
            "Epoch 54/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.2605 - accuracy: 0.9131 - val_loss: 0.2383 - val_accuracy: 0.9200\n",
            "Epoch 55/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2512 - accuracy: 0.9162 - val_loss: 0.2121 - val_accuracy: 0.9286\n",
            "Epoch 56/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2558 - accuracy: 0.9144 - val_loss: 0.2156 - val_accuracy: 0.9278\n",
            "Epoch 57/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2437 - accuracy: 0.9174 - val_loss: 0.2309 - val_accuracy: 0.9239\n",
            "Epoch 58/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2561 - accuracy: 0.9126 - val_loss: 0.2398 - val_accuracy: 0.9204\n",
            "Epoch 59/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2461 - accuracy: 0.9174 - val_loss: 0.2317 - val_accuracy: 0.9254\n",
            "Epoch 60/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2405 - accuracy: 0.9209 - val_loss: 0.2299 - val_accuracy: 0.9221\n",
            "Epoch 61/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2551 - accuracy: 0.9149 - val_loss: 0.2111 - val_accuracy: 0.9301\n",
            "Epoch 62/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2369 - accuracy: 0.9201 - val_loss: 0.2231 - val_accuracy: 0.9275\n",
            "Epoch 63/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2375 - accuracy: 0.9219 - val_loss: 0.2048 - val_accuracy: 0.9300\n",
            "Epoch 64/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2378 - accuracy: 0.9205 - val_loss: 0.1949 - val_accuracy: 0.9391\n",
            "Epoch 65/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2372 - accuracy: 0.9216 - val_loss: 0.2276 - val_accuracy: 0.9235\n",
            "Epoch 66/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2406 - accuracy: 0.9209 - val_loss: 0.1850 - val_accuracy: 0.9357\n",
            "Epoch 67/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2416 - accuracy: 0.9213 - val_loss: 0.2431 - val_accuracy: 0.9207\n",
            "Epoch 68/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2406 - accuracy: 0.9203 - val_loss: 0.2024 - val_accuracy: 0.9345\n",
            "Epoch 69/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2288 - accuracy: 0.9233 - val_loss: 0.2093 - val_accuracy: 0.9286\n",
            "Epoch 70/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2314 - accuracy: 0.9240 - val_loss: 0.2209 - val_accuracy: 0.9257\n",
            "Epoch 71/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2346 - accuracy: 0.9231 - val_loss: 0.2194 - val_accuracy: 0.9257\n",
            "Epoch 72/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2330 - accuracy: 0.9232 - val_loss: 0.1977 - val_accuracy: 0.9346\n",
            "Epoch 73/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2253 - accuracy: 0.9245 - val_loss: 0.2039 - val_accuracy: 0.9327\n",
            "Epoch 74/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2239 - accuracy: 0.9258 - val_loss: 0.2109 - val_accuracy: 0.9325\n",
            "Epoch 75/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2288 - accuracy: 0.9243 - val_loss: 0.2650 - val_accuracy: 0.9115\n",
            "Epoch 76/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2268 - accuracy: 0.9256 - val_loss: 0.1909 - val_accuracy: 0.9399\n",
            "Epoch 77/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2247 - accuracy: 0.9274 - val_loss: 0.2296 - val_accuracy: 0.9255\n",
            "Epoch 78/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2267 - accuracy: 0.9239 - val_loss: 0.2078 - val_accuracy: 0.9321\n",
            "Epoch 79/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2256 - accuracy: 0.9254 - val_loss: 0.1852 - val_accuracy: 0.9375\n",
            "Epoch 80/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2243 - accuracy: 0.9255 - val_loss: 0.1860 - val_accuracy: 0.9367\n",
            "Epoch 81/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2221 - accuracy: 0.9279 - val_loss: 0.1772 - val_accuracy: 0.9413\n",
            "Epoch 82/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2208 - accuracy: 0.9262 - val_loss: 0.1728 - val_accuracy: 0.9407\n",
            "Epoch 83/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2189 - accuracy: 0.9280 - val_loss: 0.2082 - val_accuracy: 0.9311\n",
            "Epoch 84/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2222 - accuracy: 0.9267 - val_loss: 0.1976 - val_accuracy: 0.9324\n",
            "Epoch 85/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2213 - accuracy: 0.9275 - val_loss: 0.1895 - val_accuracy: 0.9384\n",
            "Epoch 86/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2201 - accuracy: 0.9281 - val_loss: 0.1989 - val_accuracy: 0.9349\n",
            "Epoch 87/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2226 - accuracy: 0.9262 - val_loss: 0.1954 - val_accuracy: 0.9363\n",
            "Epoch 88/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2248 - accuracy: 0.9250 - val_loss: 0.2003 - val_accuracy: 0.9357\n",
            "Epoch 89/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2250 - accuracy: 0.9283 - val_loss: 0.2073 - val_accuracy: 0.9285\n",
            "Epoch 90/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2161 - accuracy: 0.9304 - val_loss: 0.2148 - val_accuracy: 0.9321\n",
            "Epoch 91/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2064 - accuracy: 0.9328 - val_loss: 0.2305 - val_accuracy: 0.9261\n",
            "Epoch 92/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2193 - accuracy: 0.9280 - val_loss: 0.2141 - val_accuracy: 0.9303\n",
            "Epoch 93/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2081 - accuracy: 0.9322 - val_loss: 0.2077 - val_accuracy: 0.9300\n",
            "Epoch 94/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2084 - accuracy: 0.9304 - val_loss: 0.2313 - val_accuracy: 0.9222\n",
            "Epoch 95/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2113 - accuracy: 0.9313 - val_loss: 0.2165 - val_accuracy: 0.9264\n",
            "Epoch 96/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2078 - accuracy: 0.9322 - val_loss: 0.1871 - val_accuracy: 0.9398\n",
            "Epoch 97/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2048 - accuracy: 0.9326 - val_loss: 0.1996 - val_accuracy: 0.9321\n",
            "Epoch 98/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2154 - accuracy: 0.9301 - val_loss: 0.1962 - val_accuracy: 0.9347\n",
            "Epoch 99/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2043 - accuracy: 0.9324 - val_loss: 0.1925 - val_accuracy: 0.9364\n",
            "Epoch 100/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1982 - accuracy: 0.9334 - val_loss: 0.1756 - val_accuracy: 0.9416\n",
            "Epoch 101/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2140 - accuracy: 0.9313 - val_loss: 0.1733 - val_accuracy: 0.9412\n",
            "Epoch 102/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2117 - accuracy: 0.9321 - val_loss: 0.1944 - val_accuracy: 0.9363\n",
            "Epoch 103/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2082 - accuracy: 0.9332 - val_loss: 0.1721 - val_accuracy: 0.9437\n",
            "Epoch 104/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2088 - accuracy: 0.9332 - val_loss: 0.1994 - val_accuracy: 0.9350\n",
            "Epoch 105/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2069 - accuracy: 0.9341 - val_loss: 0.2048 - val_accuracy: 0.9328\n",
            "Epoch 106/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2134 - accuracy: 0.9310 - val_loss: 0.1989 - val_accuracy: 0.9342\n",
            "Epoch 107/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1984 - accuracy: 0.9348 - val_loss: 0.1638 - val_accuracy: 0.9449\n",
            "Epoch 108/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2021 - accuracy: 0.9357 - val_loss: 0.1879 - val_accuracy: 0.9388\n",
            "Epoch 109/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2020 - accuracy: 0.9343 - val_loss: 0.1770 - val_accuracy: 0.9378\n",
            "Epoch 110/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2082 - accuracy: 0.9335 - val_loss: 0.1561 - val_accuracy: 0.9477\n",
            "Epoch 111/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2051 - accuracy: 0.9342 - val_loss: 0.1885 - val_accuracy: 0.9396\n",
            "Epoch 112/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1995 - accuracy: 0.9356 - val_loss: 0.2010 - val_accuracy: 0.9353\n",
            "Epoch 113/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1978 - accuracy: 0.9362 - val_loss: 0.2072 - val_accuracy: 0.9286\n",
            "Epoch 114/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.2029 - accuracy: 0.9341 - val_loss: 0.1651 - val_accuracy: 0.9437\n",
            "Epoch 115/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1921 - accuracy: 0.9386 - val_loss: 0.1875 - val_accuracy: 0.9375\n",
            "Epoch 116/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2131 - accuracy: 0.9327 - val_loss: 0.2024 - val_accuracy: 0.9338\n",
            "Epoch 117/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1985 - accuracy: 0.9346 - val_loss: 0.2076 - val_accuracy: 0.9293\n",
            "Epoch 118/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2005 - accuracy: 0.9346 - val_loss: 0.1975 - val_accuracy: 0.9324\n",
            "Epoch 119/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2001 - accuracy: 0.9354 - val_loss: 0.1763 - val_accuracy: 0.9398\n",
            "Epoch 120/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2009 - accuracy: 0.9342 - val_loss: 0.1988 - val_accuracy: 0.9356\n",
            "Epoch 121/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2023 - accuracy: 0.9340 - val_loss: 0.1660 - val_accuracy: 0.9434\n",
            "Epoch 122/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1940 - accuracy: 0.9374 - val_loss: 0.1745 - val_accuracy: 0.9428\n",
            "Epoch 123/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2007 - accuracy: 0.9352 - val_loss: 0.1551 - val_accuracy: 0.9480\n",
            "Epoch 124/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1968 - accuracy: 0.9359 - val_loss: 0.1577 - val_accuracy: 0.9462\n",
            "Epoch 125/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1915 - accuracy: 0.9394 - val_loss: 0.1980 - val_accuracy: 0.9345\n",
            "Epoch 126/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1952 - accuracy: 0.9362 - val_loss: 0.1813 - val_accuracy: 0.9414\n",
            "Epoch 127/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1855 - accuracy: 0.9403 - val_loss: 0.2059 - val_accuracy: 0.9332\n",
            "Epoch 128/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2028 - accuracy: 0.9364 - val_loss: 0.1676 - val_accuracy: 0.9435\n",
            "Epoch 129/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1824 - accuracy: 0.9404 - val_loss: 0.1820 - val_accuracy: 0.9395\n",
            "Epoch 130/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1946 - accuracy: 0.9388 - val_loss: 0.1867 - val_accuracy: 0.9400\n",
            "Epoch 131/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1950 - accuracy: 0.9349 - val_loss: 0.1678 - val_accuracy: 0.9412\n",
            "Epoch 132/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1956 - accuracy: 0.9374 - val_loss: 0.1726 - val_accuracy: 0.9400\n",
            "Epoch 133/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1920 - accuracy: 0.9381 - val_loss: 0.2337 - val_accuracy: 0.9236\n",
            "Epoch 134/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1927 - accuracy: 0.9398 - val_loss: 0.1947 - val_accuracy: 0.9363\n",
            "Epoch 135/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1952 - accuracy: 0.9382 - val_loss: 0.1492 - val_accuracy: 0.9525\n",
            "Epoch 136/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1920 - accuracy: 0.9392 - val_loss: 0.1908 - val_accuracy: 0.9357\n",
            "Epoch 137/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1880 - accuracy: 0.9384 - val_loss: 0.1571 - val_accuracy: 0.9492\n",
            "Epoch 138/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1899 - accuracy: 0.9385 - val_loss: 0.1873 - val_accuracy: 0.9388\n",
            "Epoch 139/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.2003 - accuracy: 0.9352 - val_loss: 0.1591 - val_accuracy: 0.9488\n",
            "Epoch 140/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1828 - accuracy: 0.9399 - val_loss: 0.1699 - val_accuracy: 0.9448\n",
            "Epoch 141/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1904 - accuracy: 0.9384 - val_loss: 0.1670 - val_accuracy: 0.9428\n",
            "Epoch 142/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1935 - accuracy: 0.9394 - val_loss: 0.1834 - val_accuracy: 0.9409\n",
            "Epoch 143/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1946 - accuracy: 0.9386 - val_loss: 0.1729 - val_accuracy: 0.9448\n",
            "Epoch 144/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1813 - accuracy: 0.9424 - val_loss: 0.1651 - val_accuracy: 0.9431\n",
            "Epoch 145/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1853 - accuracy: 0.9400 - val_loss: 0.1726 - val_accuracy: 0.9445\n",
            "Epoch 146/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1897 - accuracy: 0.9380 - val_loss: 0.1602 - val_accuracy: 0.9484\n",
            "Epoch 147/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1941 - accuracy: 0.9383 - val_loss: 0.1905 - val_accuracy: 0.9361\n",
            "Epoch 148/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1787 - accuracy: 0.9434 - val_loss: 0.1654 - val_accuracy: 0.9487\n",
            "Epoch 149/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1800 - accuracy: 0.9409 - val_loss: 0.1705 - val_accuracy: 0.9434\n",
            "Epoch 150/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1871 - accuracy: 0.9407 - val_loss: 0.1836 - val_accuracy: 0.9406\n",
            "Epoch 151/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1950 - accuracy: 0.9395 - val_loss: 0.1716 - val_accuracy: 0.9452\n",
            "Epoch 152/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1837 - accuracy: 0.9407 - val_loss: 0.1718 - val_accuracy: 0.9452\n",
            "Epoch 153/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1852 - accuracy: 0.9421 - val_loss: 0.1620 - val_accuracy: 0.9491\n",
            "Epoch 154/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1786 - accuracy: 0.9426 - val_loss: 0.1778 - val_accuracy: 0.9420\n",
            "Epoch 155/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1760 - accuracy: 0.9434 - val_loss: 0.1696 - val_accuracy: 0.9472\n",
            "Epoch 156/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1897 - accuracy: 0.9402 - val_loss: 0.1666 - val_accuracy: 0.9456\n",
            "Epoch 157/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1840 - accuracy: 0.9410 - val_loss: 0.1673 - val_accuracy: 0.9495\n",
            "Epoch 158/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1812 - accuracy: 0.9409 - val_loss: 0.1754 - val_accuracy: 0.9431\n",
            "Epoch 159/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1808 - accuracy: 0.9433 - val_loss: 0.1447 - val_accuracy: 0.9509\n",
            "Epoch 160/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1877 - accuracy: 0.9411 - val_loss: 0.1626 - val_accuracy: 0.9476\n",
            "Epoch 161/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1800 - accuracy: 0.9414 - val_loss: 0.1706 - val_accuracy: 0.9419\n",
            "Epoch 162/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1818 - accuracy: 0.9431 - val_loss: 0.1665 - val_accuracy: 0.9456\n",
            "Epoch 163/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1901 - accuracy: 0.9396 - val_loss: 0.1682 - val_accuracy: 0.9455\n",
            "Epoch 164/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1751 - accuracy: 0.9445 - val_loss: 0.1650 - val_accuracy: 0.9449\n",
            "Epoch 165/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1807 - accuracy: 0.9418 - val_loss: 0.1557 - val_accuracy: 0.9495\n",
            "Epoch 166/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1880 - accuracy: 0.9424 - val_loss: 0.1707 - val_accuracy: 0.9448\n",
            "Epoch 167/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1704 - accuracy: 0.9448 - val_loss: 0.1496 - val_accuracy: 0.9492\n",
            "Epoch 168/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1805 - accuracy: 0.9434 - val_loss: 0.1540 - val_accuracy: 0.9506\n",
            "Epoch 169/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1847 - accuracy: 0.9411 - val_loss: 0.1715 - val_accuracy: 0.9414\n",
            "Epoch 170/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1751 - accuracy: 0.9457 - val_loss: 0.2118 - val_accuracy: 0.9331\n",
            "Epoch 171/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1859 - accuracy: 0.9408 - val_loss: 0.1711 - val_accuracy: 0.9456\n",
            "Epoch 172/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1855 - accuracy: 0.9418 - val_loss: 0.1683 - val_accuracy: 0.9437\n",
            "Epoch 173/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1839 - accuracy: 0.9426 - val_loss: 0.1548 - val_accuracy: 0.9497\n",
            "Epoch 174/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1875 - accuracy: 0.9414 - val_loss: 0.1944 - val_accuracy: 0.9382\n",
            "Epoch 175/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1706 - accuracy: 0.9453 - val_loss: 0.1521 - val_accuracy: 0.9474\n",
            "Epoch 176/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1743 - accuracy: 0.9441 - val_loss: 0.1377 - val_accuracy: 0.9536\n",
            "Epoch 177/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1755 - accuracy: 0.9453 - val_loss: 0.1853 - val_accuracy: 0.9437\n",
            "Epoch 178/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1833 - accuracy: 0.9427 - val_loss: 0.1809 - val_accuracy: 0.9423\n",
            "Epoch 179/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1791 - accuracy: 0.9431 - val_loss: 0.1652 - val_accuracy: 0.9448\n",
            "Epoch 180/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1767 - accuracy: 0.9443 - val_loss: 0.1437 - val_accuracy: 0.9554\n",
            "Epoch 181/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1819 - accuracy: 0.9432 - val_loss: 0.1690 - val_accuracy: 0.9480\n",
            "Epoch 182/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1739 - accuracy: 0.9470 - val_loss: 0.1460 - val_accuracy: 0.9532\n",
            "Epoch 183/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1820 - accuracy: 0.9432 - val_loss: 0.1550 - val_accuracy: 0.9495\n",
            "Epoch 184/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1734 - accuracy: 0.9451 - val_loss: 0.1612 - val_accuracy: 0.9467\n",
            "Epoch 185/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1694 - accuracy: 0.9458 - val_loss: 0.1903 - val_accuracy: 0.9377\n",
            "Epoch 186/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1740 - accuracy: 0.9445 - val_loss: 0.1746 - val_accuracy: 0.9438\n",
            "Epoch 187/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1671 - accuracy: 0.9465 - val_loss: 0.1553 - val_accuracy: 0.9483\n",
            "Epoch 188/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1789 - accuracy: 0.9428 - val_loss: 0.1602 - val_accuracy: 0.9449\n",
            "Epoch 189/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1790 - accuracy: 0.9434 - val_loss: 0.1649 - val_accuracy: 0.9435\n",
            "Epoch 190/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1669 - accuracy: 0.9471 - val_loss: 0.1699 - val_accuracy: 0.9438\n",
            "Epoch 191/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1771 - accuracy: 0.9456 - val_loss: 0.1621 - val_accuracy: 0.9458\n",
            "Epoch 192/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1665 - accuracy: 0.9477 - val_loss: 0.1700 - val_accuracy: 0.9458\n",
            "Epoch 193/1000\n",
            "858/858 [==============================] - 11s 13ms/step - loss: 0.1766 - accuracy: 0.9439 - val_loss: 0.1474 - val_accuracy: 0.9513\n",
            "Epoch 194/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1680 - accuracy: 0.9485 - val_loss: 0.1669 - val_accuracy: 0.9460\n",
            "Epoch 195/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1774 - accuracy: 0.9444 - val_loss: 0.1358 - val_accuracy: 0.9557\n",
            "Epoch 196/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1787 - accuracy: 0.9448 - val_loss: 0.1836 - val_accuracy: 0.9393\n",
            "Epoch 197/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1709 - accuracy: 0.9468 - val_loss: 0.1703 - val_accuracy: 0.9459\n",
            "Epoch 198/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1788 - accuracy: 0.9442 - val_loss: 0.1510 - val_accuracy: 0.9529\n",
            "Epoch 199/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1735 - accuracy: 0.9461 - val_loss: 0.1672 - val_accuracy: 0.9467\n",
            "Epoch 200/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1719 - accuracy: 0.9458 - val_loss: 0.1709 - val_accuracy: 0.9465\n",
            "Epoch 201/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1671 - accuracy: 0.9471 - val_loss: 0.1405 - val_accuracy: 0.9529\n",
            "Epoch 202/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1657 - accuracy: 0.9475 - val_loss: 0.1523 - val_accuracy: 0.9516\n",
            "Epoch 203/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1702 - accuracy: 0.9455 - val_loss: 0.1670 - val_accuracy: 0.9472\n",
            "Epoch 204/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1754 - accuracy: 0.9453 - val_loss: 0.1521 - val_accuracy: 0.9526\n",
            "Epoch 205/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1719 - accuracy: 0.9470 - val_loss: 0.1778 - val_accuracy: 0.9427\n",
            "Epoch 206/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1643 - accuracy: 0.9474 - val_loss: 0.1694 - val_accuracy: 0.9412\n",
            "Epoch 207/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1747 - accuracy: 0.9458 - val_loss: 0.1574 - val_accuracy: 0.9460\n",
            "Epoch 208/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1713 - accuracy: 0.9465 - val_loss: 0.1712 - val_accuracy: 0.9446\n",
            "Epoch 209/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1701 - accuracy: 0.9473 - val_loss: 0.1398 - val_accuracy: 0.9559\n",
            "Epoch 210/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1739 - accuracy: 0.9458 - val_loss: 0.1478 - val_accuracy: 0.9516\n",
            "Epoch 211/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1694 - accuracy: 0.9463 - val_loss: 0.1627 - val_accuracy: 0.9484\n",
            "Epoch 212/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1714 - accuracy: 0.9460 - val_loss: 0.1530 - val_accuracy: 0.9490\n",
            "Epoch 213/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1721 - accuracy: 0.9455 - val_loss: 0.1530 - val_accuracy: 0.9534\n",
            "Epoch 214/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1640 - accuracy: 0.9502 - val_loss: 0.1536 - val_accuracy: 0.9513\n",
            "Epoch 215/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1543 - accuracy: 0.9522 - val_loss: 0.1375 - val_accuracy: 0.9534\n",
            "Epoch 216/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1850 - accuracy: 0.9438 - val_loss: 0.1795 - val_accuracy: 0.9438\n",
            "Epoch 217/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1655 - accuracy: 0.9489 - val_loss: 0.1444 - val_accuracy: 0.9502\n",
            "Epoch 218/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1683 - accuracy: 0.9474 - val_loss: 0.1439 - val_accuracy: 0.9529\n",
            "Epoch 219/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1614 - accuracy: 0.9478 - val_loss: 0.1465 - val_accuracy: 0.9555\n",
            "Epoch 220/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1713 - accuracy: 0.9468 - val_loss: 0.1643 - val_accuracy: 0.9460\n",
            "Epoch 221/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1720 - accuracy: 0.9458 - val_loss: 0.1526 - val_accuracy: 0.9509\n",
            "Epoch 222/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1623 - accuracy: 0.9476 - val_loss: 0.1730 - val_accuracy: 0.9472\n",
            "Epoch 223/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1774 - accuracy: 0.9459 - val_loss: 0.1714 - val_accuracy: 0.9451\n",
            "Epoch 224/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1642 - accuracy: 0.9473 - val_loss: 0.1590 - val_accuracy: 0.9526\n",
            "Epoch 225/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1649 - accuracy: 0.9483 - val_loss: 0.1546 - val_accuracy: 0.9509\n",
            "Epoch 226/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1694 - accuracy: 0.9465 - val_loss: 0.1466 - val_accuracy: 0.9571\n",
            "Epoch 227/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1673 - accuracy: 0.9471 - val_loss: 0.1355 - val_accuracy: 0.9541\n",
            "Epoch 228/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1590 - accuracy: 0.9493 - val_loss: 0.1667 - val_accuracy: 0.9437\n",
            "Epoch 229/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1733 - accuracy: 0.9469 - val_loss: 0.1677 - val_accuracy: 0.9439\n",
            "Epoch 230/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1753 - accuracy: 0.9464 - val_loss: 0.1390 - val_accuracy: 0.9544\n",
            "Epoch 231/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1621 - accuracy: 0.9484 - val_loss: 0.1763 - val_accuracy: 0.9424\n",
            "Epoch 232/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1663 - accuracy: 0.9489 - val_loss: 0.1669 - val_accuracy: 0.9474\n",
            "Epoch 233/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1761 - accuracy: 0.9459 - val_loss: 0.1867 - val_accuracy: 0.9423\n",
            "Epoch 234/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1629 - accuracy: 0.9482 - val_loss: 0.1426 - val_accuracy: 0.9520\n",
            "Epoch 235/1000\n",
            "858/858 [==============================] - 12s 13ms/step - loss: 0.1644 - accuracy: 0.9501 - val_loss: 0.1765 - val_accuracy: 0.9465\n",
            "Epoch 236/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1614 - accuracy: 0.9499 - val_loss: 0.1434 - val_accuracy: 0.9562\n",
            "Epoch 237/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1667 - accuracy: 0.9478 - val_loss: 0.1482 - val_accuracy: 0.9511\n",
            "Epoch 238/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1655 - accuracy: 0.9489 - val_loss: 0.1649 - val_accuracy: 0.9479\n",
            "Epoch 239/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1611 - accuracy: 0.9503 - val_loss: 0.1528 - val_accuracy: 0.9513\n",
            "Epoch 240/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1643 - accuracy: 0.9478 - val_loss: 0.1372 - val_accuracy: 0.9565\n",
            "Epoch 241/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1632 - accuracy: 0.9504 - val_loss: 0.1555 - val_accuracy: 0.9505\n",
            "Epoch 242/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1674 - accuracy: 0.9473 - val_loss: 0.1458 - val_accuracy: 0.9552\n",
            "Epoch 243/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1661 - accuracy: 0.9500 - val_loss: 0.1545 - val_accuracy: 0.9520\n",
            "Epoch 244/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1614 - accuracy: 0.9505 - val_loss: 0.1643 - val_accuracy: 0.9497\n",
            "Epoch 245/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1605 - accuracy: 0.9510 - val_loss: 0.1504 - val_accuracy: 0.9516\n",
            "Epoch 246/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1595 - accuracy: 0.9505 - val_loss: 0.1471 - val_accuracy: 0.9502\n",
            "Epoch 247/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1598 - accuracy: 0.9512 - val_loss: 0.1854 - val_accuracy: 0.9395\n",
            "Epoch 248/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1649 - accuracy: 0.9470 - val_loss: 0.1757 - val_accuracy: 0.9416\n",
            "Epoch 249/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1663 - accuracy: 0.9489 - val_loss: 0.1310 - val_accuracy: 0.9571\n",
            "Epoch 250/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1654 - accuracy: 0.9493 - val_loss: 0.1563 - val_accuracy: 0.9501\n",
            "Epoch 251/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1658 - accuracy: 0.9492 - val_loss: 0.1428 - val_accuracy: 0.9552\n",
            "Epoch 252/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1637 - accuracy: 0.9497 - val_loss: 0.1413 - val_accuracy: 0.9550\n",
            "Epoch 253/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1618 - accuracy: 0.9492 - val_loss: 0.1506 - val_accuracy: 0.9541\n",
            "Epoch 254/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1645 - accuracy: 0.9475 - val_loss: 0.1576 - val_accuracy: 0.9484\n",
            "Epoch 255/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1650 - accuracy: 0.9491 - val_loss: 0.1328 - val_accuracy: 0.9537\n",
            "Epoch 256/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1671 - accuracy: 0.9494 - val_loss: 0.1580 - val_accuracy: 0.9508\n",
            "Epoch 257/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1588 - accuracy: 0.9506 - val_loss: 0.1457 - val_accuracy: 0.9527\n",
            "Epoch 258/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1615 - accuracy: 0.9510 - val_loss: 0.1583 - val_accuracy: 0.9484\n",
            "Epoch 259/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1632 - accuracy: 0.9479 - val_loss: 0.1500 - val_accuracy: 0.9512\n",
            "Epoch 260/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1522 - accuracy: 0.9521 - val_loss: 0.1390 - val_accuracy: 0.9544\n",
            "Epoch 261/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1638 - accuracy: 0.9489 - val_loss: 0.1589 - val_accuracy: 0.9472\n",
            "Epoch 262/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1618 - accuracy: 0.9501 - val_loss: 0.1548 - val_accuracy: 0.9512\n",
            "Epoch 263/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1560 - accuracy: 0.9515 - val_loss: 0.1493 - val_accuracy: 0.9518\n",
            "Epoch 264/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1580 - accuracy: 0.9504 - val_loss: 0.1407 - val_accuracy: 0.9568\n",
            "Epoch 265/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1613 - accuracy: 0.9494 - val_loss: 0.1519 - val_accuracy: 0.9515\n",
            "Epoch 266/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1585 - accuracy: 0.9522 - val_loss: 0.1434 - val_accuracy: 0.9526\n",
            "Epoch 267/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1630 - accuracy: 0.9489 - val_loss: 0.1532 - val_accuracy: 0.9513\n",
            "Epoch 268/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1627 - accuracy: 0.9496 - val_loss: 0.1550 - val_accuracy: 0.9490\n",
            "Epoch 269/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1696 - accuracy: 0.9485 - val_loss: 0.1615 - val_accuracy: 0.9487\n",
            "Epoch 270/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1597 - accuracy: 0.9516 - val_loss: 0.1685 - val_accuracy: 0.9490\n",
            "Epoch 271/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1615 - accuracy: 0.9492 - val_loss: 0.1346 - val_accuracy: 0.9547\n",
            "Epoch 272/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1625 - accuracy: 0.9521 - val_loss: 0.1415 - val_accuracy: 0.9516\n",
            "Epoch 273/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1586 - accuracy: 0.9497 - val_loss: 0.1435 - val_accuracy: 0.9540\n",
            "Epoch 274/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1628 - accuracy: 0.9514 - val_loss: 0.1177 - val_accuracy: 0.9614\n",
            "Epoch 275/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1603 - accuracy: 0.9502 - val_loss: 0.1471 - val_accuracy: 0.9494\n",
            "Epoch 276/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1623 - accuracy: 0.9514 - val_loss: 0.1255 - val_accuracy: 0.9605\n",
            "Epoch 277/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1610 - accuracy: 0.9515 - val_loss: 0.1458 - val_accuracy: 0.9537\n",
            "Epoch 278/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1573 - accuracy: 0.9517 - val_loss: 0.1409 - val_accuracy: 0.9564\n",
            "Epoch 279/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1637 - accuracy: 0.9504 - val_loss: 0.1682 - val_accuracy: 0.9487\n",
            "Epoch 280/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1594 - accuracy: 0.9496 - val_loss: 0.1398 - val_accuracy: 0.9547\n",
            "Epoch 281/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1593 - accuracy: 0.9510 - val_loss: 0.1639 - val_accuracy: 0.9463\n",
            "Epoch 282/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1607 - accuracy: 0.9509 - val_loss: 0.1670 - val_accuracy: 0.9490\n",
            "Epoch 283/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1538 - accuracy: 0.9533 - val_loss: 0.1542 - val_accuracy: 0.9480\n",
            "Epoch 284/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1607 - accuracy: 0.9518 - val_loss: 0.1421 - val_accuracy: 0.9545\n",
            "Epoch 285/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1568 - accuracy: 0.9521 - val_loss: 0.1402 - val_accuracy: 0.9555\n",
            "Epoch 286/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1609 - accuracy: 0.9503 - val_loss: 0.1390 - val_accuracy: 0.9566\n",
            "Epoch 287/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1552 - accuracy: 0.9521 - val_loss: 0.1395 - val_accuracy: 0.9527\n",
            "Epoch 288/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1679 - accuracy: 0.9505 - val_loss: 0.1423 - val_accuracy: 0.9544\n",
            "Epoch 289/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1475 - accuracy: 0.9548 - val_loss: 0.1392 - val_accuracy: 0.9543\n",
            "Epoch 290/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1705 - accuracy: 0.9475 - val_loss: 0.1210 - val_accuracy: 0.9612\n",
            "Epoch 291/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1566 - accuracy: 0.9515 - val_loss: 0.1515 - val_accuracy: 0.9516\n",
            "Epoch 292/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1480 - accuracy: 0.9540 - val_loss: 0.1365 - val_accuracy: 0.9573\n",
            "Epoch 293/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1584 - accuracy: 0.9513 - val_loss: 0.1329 - val_accuracy: 0.9566\n",
            "Epoch 294/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1585 - accuracy: 0.9540 - val_loss: 0.1667 - val_accuracy: 0.9474\n",
            "Epoch 295/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1525 - accuracy: 0.9526 - val_loss: 0.1794 - val_accuracy: 0.9412\n",
            "Epoch 296/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1568 - accuracy: 0.9524 - val_loss: 0.1373 - val_accuracy: 0.9538\n",
            "Epoch 297/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1642 - accuracy: 0.9513 - val_loss: 0.1322 - val_accuracy: 0.9571\n",
            "Epoch 298/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1598 - accuracy: 0.9495 - val_loss: 0.1464 - val_accuracy: 0.9575\n",
            "Epoch 299/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1583 - accuracy: 0.9514 - val_loss: 0.1405 - val_accuracy: 0.9530\n",
            "Epoch 300/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1573 - accuracy: 0.9519 - val_loss: 0.1380 - val_accuracy: 0.9561\n",
            "Epoch 301/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1614 - accuracy: 0.9501 - val_loss: 0.1448 - val_accuracy: 0.9537\n",
            "Epoch 302/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1600 - accuracy: 0.9505 - val_loss: 0.1417 - val_accuracy: 0.9520\n",
            "Epoch 303/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1537 - accuracy: 0.9529 - val_loss: 0.1383 - val_accuracy: 0.9561\n",
            "Epoch 304/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1439 - accuracy: 0.9556 - val_loss: 0.1460 - val_accuracy: 0.9526\n",
            "Epoch 305/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1661 - accuracy: 0.9488 - val_loss: 0.1503 - val_accuracy: 0.9518\n",
            "Epoch 306/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1462 - accuracy: 0.9549 - val_loss: 0.1486 - val_accuracy: 0.9558\n",
            "Epoch 307/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1547 - accuracy: 0.9530 - val_loss: 0.1540 - val_accuracy: 0.9522\n",
            "Epoch 308/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1538 - accuracy: 0.9540 - val_loss: 0.1741 - val_accuracy: 0.9428\n",
            "Epoch 309/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1526 - accuracy: 0.9528 - val_loss: 0.1401 - val_accuracy: 0.9569\n",
            "Epoch 310/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1453 - accuracy: 0.9543 - val_loss: 0.1369 - val_accuracy: 0.9536\n",
            "Epoch 311/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1571 - accuracy: 0.9530 - val_loss: 0.1698 - val_accuracy: 0.9479\n",
            "Epoch 312/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1485 - accuracy: 0.9548 - val_loss: 0.1552 - val_accuracy: 0.9515\n",
            "Epoch 313/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1669 - accuracy: 0.9496 - val_loss: 0.1373 - val_accuracy: 0.9573\n",
            "Epoch 314/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1623 - accuracy: 0.9509 - val_loss: 0.1450 - val_accuracy: 0.9543\n",
            "Epoch 315/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1481 - accuracy: 0.9550 - val_loss: 0.1367 - val_accuracy: 0.9561\n",
            "Epoch 316/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1631 - accuracy: 0.9507 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
            "Epoch 317/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1498 - accuracy: 0.9543 - val_loss: 0.1448 - val_accuracy: 0.9568\n",
            "Epoch 318/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1531 - accuracy: 0.9537 - val_loss: 0.1545 - val_accuracy: 0.9518\n",
            "Epoch 319/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1570 - accuracy: 0.9528 - val_loss: 0.1618 - val_accuracy: 0.9498\n",
            "Epoch 320/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1525 - accuracy: 0.9532 - val_loss: 0.1597 - val_accuracy: 0.9543\n",
            "Epoch 321/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1507 - accuracy: 0.9548 - val_loss: 0.1389 - val_accuracy: 0.9568\n",
            "Epoch 322/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1542 - accuracy: 0.9533 - val_loss: 0.1593 - val_accuracy: 0.9525\n",
            "Epoch 323/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1554 - accuracy: 0.9537 - val_loss: 0.1541 - val_accuracy: 0.9519\n",
            "Epoch 324/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1617 - accuracy: 0.9516 - val_loss: 0.1661 - val_accuracy: 0.9504\n",
            "Epoch 325/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1543 - accuracy: 0.9532 - val_loss: 0.1559 - val_accuracy: 0.9513\n",
            "Epoch 326/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1597 - accuracy: 0.9517 - val_loss: 0.1568 - val_accuracy: 0.9508\n",
            "Epoch 327/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1576 - accuracy: 0.9514 - val_loss: 0.1330 - val_accuracy: 0.9594\n",
            "Epoch 328/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1542 - accuracy: 0.9534 - val_loss: 0.1367 - val_accuracy: 0.9586\n",
            "Epoch 329/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1584 - accuracy: 0.9529 - val_loss: 0.1630 - val_accuracy: 0.9498\n",
            "Epoch 330/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1510 - accuracy: 0.9547 - val_loss: 0.1406 - val_accuracy: 0.9562\n",
            "Epoch 331/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1461 - accuracy: 0.9559 - val_loss: 0.1333 - val_accuracy: 0.9573\n",
            "Epoch 332/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1570 - accuracy: 0.9535 - val_loss: 0.1619 - val_accuracy: 0.9499\n",
            "Epoch 333/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1607 - accuracy: 0.9513 - val_loss: 0.1337 - val_accuracy: 0.9596\n",
            "Epoch 334/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1547 - accuracy: 0.9543 - val_loss: 0.1305 - val_accuracy: 0.9576\n",
            "Epoch 335/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1477 - accuracy: 0.9551 - val_loss: 0.1647 - val_accuracy: 0.9460\n",
            "Epoch 336/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1485 - accuracy: 0.9549 - val_loss: 0.1451 - val_accuracy: 0.9523\n",
            "Epoch 337/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1582 - accuracy: 0.9538 - val_loss: 0.1449 - val_accuracy: 0.9529\n",
            "Epoch 338/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1414 - accuracy: 0.9572 - val_loss: 0.2444 - val_accuracy: 0.9232\n",
            "Epoch 339/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1610 - accuracy: 0.9520 - val_loss: 0.1588 - val_accuracy: 0.9494\n",
            "Epoch 340/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1656 - accuracy: 0.9512 - val_loss: 0.1304 - val_accuracy: 0.9579\n",
            "Epoch 341/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1535 - accuracy: 0.9527 - val_loss: 0.1510 - val_accuracy: 0.9551\n",
            "Epoch 342/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1474 - accuracy: 0.9543 - val_loss: 0.1378 - val_accuracy: 0.9564\n",
            "Epoch 343/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1650 - accuracy: 0.9494 - val_loss: 0.1595 - val_accuracy: 0.9501\n",
            "Epoch 344/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1548 - accuracy: 0.9533 - val_loss: 0.1165 - val_accuracy: 0.9598\n",
            "Epoch 345/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1576 - accuracy: 0.9517 - val_loss: 0.1481 - val_accuracy: 0.9534\n",
            "Epoch 346/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1570 - accuracy: 0.9524 - val_loss: 0.1444 - val_accuracy: 0.9568\n",
            "Epoch 347/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1566 - accuracy: 0.9518 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
            "Epoch 348/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1568 - accuracy: 0.9535 - val_loss: 0.1205 - val_accuracy: 0.9608\n",
            "Epoch 349/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1519 - accuracy: 0.9554 - val_loss: 0.1403 - val_accuracy: 0.9575\n",
            "Epoch 350/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1506 - accuracy: 0.9566 - val_loss: 0.1325 - val_accuracy: 0.9597\n",
            "Epoch 351/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1469 - accuracy: 0.9561 - val_loss: 0.1530 - val_accuracy: 0.9525\n",
            "Epoch 352/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1460 - accuracy: 0.9550 - val_loss: 0.1438 - val_accuracy: 0.9547\n",
            "Epoch 353/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1515 - accuracy: 0.9539 - val_loss: 0.1366 - val_accuracy: 0.9571\n",
            "Epoch 354/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1495 - accuracy: 0.9554 - val_loss: 0.1508 - val_accuracy: 0.9494\n",
            "Epoch 355/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1564 - accuracy: 0.9528 - val_loss: 0.1585 - val_accuracy: 0.9505\n",
            "Epoch 356/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1404 - accuracy: 0.9566 - val_loss: 0.1318 - val_accuracy: 0.9580\n",
            "Epoch 357/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1584 - accuracy: 0.9521 - val_loss: 0.1203 - val_accuracy: 0.9635\n",
            "Epoch 358/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1554 - accuracy: 0.9531 - val_loss: 0.1339 - val_accuracy: 0.9578\n",
            "Epoch 359/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1455 - accuracy: 0.9554 - val_loss: 0.1354 - val_accuracy: 0.9576\n",
            "Epoch 360/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1560 - accuracy: 0.9529 - val_loss: 0.1416 - val_accuracy: 0.9551\n",
            "Epoch 361/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1523 - accuracy: 0.9544 - val_loss: 0.1200 - val_accuracy: 0.9610\n",
            "Epoch 362/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1502 - accuracy: 0.9541 - val_loss: 0.1602 - val_accuracy: 0.9506\n",
            "Epoch 363/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1468 - accuracy: 0.9559 - val_loss: 0.1417 - val_accuracy: 0.9562\n",
            "Epoch 364/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1378 - accuracy: 0.9573 - val_loss: 0.1502 - val_accuracy: 0.9566\n",
            "Epoch 365/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1461 - accuracy: 0.9560 - val_loss: 0.1465 - val_accuracy: 0.9557\n",
            "Epoch 366/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1614 - accuracy: 0.9514 - val_loss: 0.1569 - val_accuracy: 0.9506\n",
            "Epoch 367/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1495 - accuracy: 0.9559 - val_loss: 0.1315 - val_accuracy: 0.9568\n",
            "Epoch 368/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1494 - accuracy: 0.9532 - val_loss: 0.1359 - val_accuracy: 0.9559\n",
            "Epoch 369/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1539 - accuracy: 0.9543 - val_loss: 0.1307 - val_accuracy: 0.9601\n",
            "Epoch 370/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1431 - accuracy: 0.9558 - val_loss: 0.1163 - val_accuracy: 0.9615\n",
            "Epoch 371/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1485 - accuracy: 0.9552 - val_loss: 0.1258 - val_accuracy: 0.9598\n",
            "Epoch 372/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1525 - accuracy: 0.9547 - val_loss: 0.1343 - val_accuracy: 0.9571\n",
            "Epoch 373/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1474 - accuracy: 0.9567 - val_loss: 0.1353 - val_accuracy: 0.9584\n",
            "Epoch 374/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1500 - accuracy: 0.9547 - val_loss: 0.1685 - val_accuracy: 0.9474\n",
            "Epoch 375/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1501 - accuracy: 0.9541 - val_loss: 0.1716 - val_accuracy: 0.9449\n",
            "Epoch 376/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1546 - accuracy: 0.9536 - val_loss: 0.1630 - val_accuracy: 0.9498\n",
            "Epoch 377/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1473 - accuracy: 0.9555 - val_loss: 0.1293 - val_accuracy: 0.9566\n",
            "Epoch 378/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1517 - accuracy: 0.9541 - val_loss: 0.1215 - val_accuracy: 0.9598\n",
            "Epoch 379/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1554 - accuracy: 0.9540 - val_loss: 0.1596 - val_accuracy: 0.9491\n",
            "Epoch 380/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1518 - accuracy: 0.9543 - val_loss: 0.1511 - val_accuracy: 0.9526\n",
            "Epoch 381/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1518 - accuracy: 0.9548 - val_loss: 0.1290 - val_accuracy: 0.9611\n",
            "Epoch 382/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1403 - accuracy: 0.9580 - val_loss: 0.1168 - val_accuracy: 0.9644\n",
            "Epoch 383/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1591 - accuracy: 0.9544 - val_loss: 0.1321 - val_accuracy: 0.9583\n",
            "Epoch 384/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1593 - accuracy: 0.9552 - val_loss: 0.1251 - val_accuracy: 0.9619\n",
            "Epoch 385/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1492 - accuracy: 0.9543 - val_loss: 0.1576 - val_accuracy: 0.9488\n",
            "Epoch 386/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1514 - accuracy: 0.9549 - val_loss: 0.1367 - val_accuracy: 0.9572\n",
            "Epoch 387/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1441 - accuracy: 0.9559 - val_loss: 0.1428 - val_accuracy: 0.9559\n",
            "Epoch 388/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1481 - accuracy: 0.9549 - val_loss: 0.1407 - val_accuracy: 0.9559\n",
            "Epoch 389/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1487 - accuracy: 0.9549 - val_loss: 0.1287 - val_accuracy: 0.9617\n",
            "Epoch 390/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1522 - accuracy: 0.9547 - val_loss: 0.1366 - val_accuracy: 0.9569\n",
            "Epoch 391/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1550 - accuracy: 0.9550 - val_loss: 0.1464 - val_accuracy: 0.9516\n",
            "Epoch 392/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1532 - accuracy: 0.9531 - val_loss: 0.1439 - val_accuracy: 0.9554\n",
            "Epoch 393/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1466 - accuracy: 0.9565 - val_loss: 0.1363 - val_accuracy: 0.9534\n",
            "Epoch 394/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1422 - accuracy: 0.9576 - val_loss: 0.1419 - val_accuracy: 0.9540\n",
            "Epoch 395/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1485 - accuracy: 0.9549 - val_loss: 0.1412 - val_accuracy: 0.9598\n",
            "Epoch 396/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1566 - accuracy: 0.9536 - val_loss: 0.1515 - val_accuracy: 0.9575\n",
            "Epoch 397/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1420 - accuracy: 0.9581 - val_loss: 0.1449 - val_accuracy: 0.9600\n",
            "Epoch 398/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1554 - accuracy: 0.9557 - val_loss: 0.1387 - val_accuracy: 0.9564\n",
            "Epoch 399/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1523 - accuracy: 0.9547 - val_loss: 0.1530 - val_accuracy: 0.9523\n",
            "Epoch 400/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1466 - accuracy: 0.9549 - val_loss: 0.1674 - val_accuracy: 0.9463\n",
            "Epoch 401/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1407 - accuracy: 0.9568 - val_loss: 0.1304 - val_accuracy: 0.9575\n",
            "Epoch 402/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1515 - accuracy: 0.9560 - val_loss: 0.1349 - val_accuracy: 0.9572\n",
            "Epoch 403/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1484 - accuracy: 0.9555 - val_loss: 0.1429 - val_accuracy: 0.9547\n",
            "Epoch 404/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1456 - accuracy: 0.9570 - val_loss: 0.1381 - val_accuracy: 0.9557\n",
            "Epoch 405/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1446 - accuracy: 0.9567 - val_loss: 0.1223 - val_accuracy: 0.9615\n",
            "Epoch 406/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1588 - accuracy: 0.9531 - val_loss: 0.1389 - val_accuracy: 0.9552\n",
            "Epoch 407/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1422 - accuracy: 0.9564 - val_loss: 0.1225 - val_accuracy: 0.9611\n",
            "Epoch 408/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1565 - accuracy: 0.9543 - val_loss: 0.1163 - val_accuracy: 0.9635\n",
            "Epoch 409/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1388 - accuracy: 0.9584 - val_loss: 0.1567 - val_accuracy: 0.9533\n",
            "Epoch 410/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1560 - accuracy: 0.9540 - val_loss: 0.1590 - val_accuracy: 0.9526\n",
            "Epoch 411/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1416 - accuracy: 0.9563 - val_loss: 0.1439 - val_accuracy: 0.9564\n",
            "Epoch 412/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1385 - accuracy: 0.9580 - val_loss: 0.1373 - val_accuracy: 0.9583\n",
            "Epoch 413/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1462 - accuracy: 0.9565 - val_loss: 0.1620 - val_accuracy: 0.9506\n",
            "Epoch 414/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1503 - accuracy: 0.9554 - val_loss: 0.1728 - val_accuracy: 0.9483\n",
            "Epoch 415/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1606 - accuracy: 0.9530 - val_loss: 0.1421 - val_accuracy: 0.9550\n",
            "Epoch 416/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1450 - accuracy: 0.9559 - val_loss: 0.1391 - val_accuracy: 0.9562\n",
            "Epoch 417/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1459 - accuracy: 0.9561 - val_loss: 0.1477 - val_accuracy: 0.9544\n",
            "Epoch 418/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1502 - accuracy: 0.9553 - val_loss: 0.1532 - val_accuracy: 0.9525\n",
            "Epoch 419/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1471 - accuracy: 0.9564 - val_loss: 0.1487 - val_accuracy: 0.9540\n",
            "Epoch 420/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1415 - accuracy: 0.9587 - val_loss: 0.1306 - val_accuracy: 0.9582\n",
            "Epoch 421/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1405 - accuracy: 0.9594 - val_loss: 0.1712 - val_accuracy: 0.9498\n",
            "Epoch 422/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1464 - accuracy: 0.9554 - val_loss: 0.1433 - val_accuracy: 0.9569\n",
            "Epoch 423/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1500 - accuracy: 0.9568 - val_loss: 0.1532 - val_accuracy: 0.9580\n",
            "Epoch 424/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1440 - accuracy: 0.9576 - val_loss: 0.1467 - val_accuracy: 0.9550\n",
            "Epoch 425/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1510 - accuracy: 0.9563 - val_loss: 0.1372 - val_accuracy: 0.9538\n",
            "Epoch 426/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1415 - accuracy: 0.9575 - val_loss: 0.1284 - val_accuracy: 0.9596\n",
            "Epoch 427/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1549 - accuracy: 0.9542 - val_loss: 0.1254 - val_accuracy: 0.9598\n",
            "Epoch 428/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1512 - accuracy: 0.9561 - val_loss: 0.1525 - val_accuracy: 0.9532\n",
            "Epoch 429/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1460 - accuracy: 0.9565 - val_loss: 0.1424 - val_accuracy: 0.9526\n",
            "Epoch 430/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1385 - accuracy: 0.9586 - val_loss: 0.1259 - val_accuracy: 0.9618\n",
            "Epoch 431/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1459 - accuracy: 0.9574 - val_loss: 0.1421 - val_accuracy: 0.9548\n",
            "Epoch 432/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1455 - accuracy: 0.9575 - val_loss: 0.1588 - val_accuracy: 0.9495\n",
            "Epoch 433/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1448 - accuracy: 0.9561 - val_loss: 0.1388 - val_accuracy: 0.9589\n",
            "Epoch 434/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1433 - accuracy: 0.9571 - val_loss: 0.1494 - val_accuracy: 0.9532\n",
            "Epoch 435/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1410 - accuracy: 0.9579 - val_loss: 0.1238 - val_accuracy: 0.9597\n",
            "Epoch 436/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1448 - accuracy: 0.9574 - val_loss: 0.1395 - val_accuracy: 0.9583\n",
            "Epoch 437/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1462 - accuracy: 0.9566 - val_loss: 0.1432 - val_accuracy: 0.9584\n",
            "Epoch 438/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1403 - accuracy: 0.9579 - val_loss: 0.1218 - val_accuracy: 0.9607\n",
            "Epoch 439/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1480 - accuracy: 0.9554 - val_loss: 0.1834 - val_accuracy: 0.9455\n",
            "Epoch 440/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1421 - accuracy: 0.9586 - val_loss: 0.1682 - val_accuracy: 0.9526\n",
            "Epoch 441/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1390 - accuracy: 0.9587 - val_loss: 0.1310 - val_accuracy: 0.9596\n",
            "Epoch 442/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1555 - accuracy: 0.9543 - val_loss: 0.1485 - val_accuracy: 0.9548\n",
            "Epoch 443/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1395 - accuracy: 0.9594 - val_loss: 0.1992 - val_accuracy: 0.9389\n",
            "Epoch 444/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1556 - accuracy: 0.9552 - val_loss: 0.1272 - val_accuracy: 0.9631\n",
            "Epoch 445/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1483 - accuracy: 0.9557 - val_loss: 0.1382 - val_accuracy: 0.9568\n",
            "Epoch 446/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1435 - accuracy: 0.9575 - val_loss: 0.1336 - val_accuracy: 0.9604\n",
            "Epoch 447/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1413 - accuracy: 0.9578 - val_loss: 0.1518 - val_accuracy: 0.9565\n",
            "Epoch 448/1000\n",
            "858/858 [==============================] - 13s 15ms/step - loss: 0.1518 - accuracy: 0.9545 - val_loss: 0.1277 - val_accuracy: 0.9610\n",
            "Epoch 449/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1412 - accuracy: 0.9577 - val_loss: 0.1322 - val_accuracy: 0.9579\n",
            "Epoch 450/1000\n",
            "858/858 [==============================] - 13s 15ms/step - loss: 0.1537 - accuracy: 0.9555 - val_loss: 0.1449 - val_accuracy: 0.9537\n",
            "Epoch 451/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1513 - accuracy: 0.9547 - val_loss: 0.1392 - val_accuracy: 0.9582\n",
            "Epoch 452/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1457 - accuracy: 0.9569 - val_loss: 0.1452 - val_accuracy: 0.9532\n",
            "Epoch 453/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1480 - accuracy: 0.9571 - val_loss: 0.1208 - val_accuracy: 0.9635\n",
            "Epoch 454/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1366 - accuracy: 0.9584 - val_loss: 0.1651 - val_accuracy: 0.9504\n",
            "Epoch 455/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1439 - accuracy: 0.9575 - val_loss: 0.1277 - val_accuracy: 0.9621\n",
            "Epoch 456/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1447 - accuracy: 0.9580 - val_loss: 0.1429 - val_accuracy: 0.9597\n",
            "Epoch 457/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1443 - accuracy: 0.9560 - val_loss: 0.1159 - val_accuracy: 0.9658\n",
            "Epoch 458/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1458 - accuracy: 0.9568 - val_loss: 0.1326 - val_accuracy: 0.9587\n",
            "Epoch 459/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1479 - accuracy: 0.9567 - val_loss: 0.1543 - val_accuracy: 0.9545\n",
            "Epoch 460/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1500 - accuracy: 0.9565 - val_loss: 0.1298 - val_accuracy: 0.9593\n",
            "Epoch 461/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1506 - accuracy: 0.9565 - val_loss: 0.1632 - val_accuracy: 0.9477\n",
            "Epoch 462/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1470 - accuracy: 0.9575 - val_loss: 0.1499 - val_accuracy: 0.9536\n",
            "Epoch 463/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1396 - accuracy: 0.9586 - val_loss: 0.1202 - val_accuracy: 0.9639\n",
            "Epoch 464/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1504 - accuracy: 0.9562 - val_loss: 0.1386 - val_accuracy: 0.9573\n",
            "Epoch 465/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1399 - accuracy: 0.9576 - val_loss: 0.1346 - val_accuracy: 0.9590\n",
            "Epoch 466/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1443 - accuracy: 0.9567 - val_loss: 0.1346 - val_accuracy: 0.9578\n",
            "Epoch 467/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1482 - accuracy: 0.9549 - val_loss: 0.1874 - val_accuracy: 0.9421\n",
            "Epoch 468/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1476 - accuracy: 0.9559 - val_loss: 0.1382 - val_accuracy: 0.9573\n",
            "Epoch 469/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1412 - accuracy: 0.9583 - val_loss: 0.1207 - val_accuracy: 0.9605\n",
            "Epoch 470/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1452 - accuracy: 0.9572 - val_loss: 0.1193 - val_accuracy: 0.9597\n",
            "Epoch 471/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1423 - accuracy: 0.9571 - val_loss: 0.1483 - val_accuracy: 0.9538\n",
            "Epoch 472/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1327 - accuracy: 0.9596 - val_loss: 0.1290 - val_accuracy: 0.9591\n",
            "Epoch 473/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1444 - accuracy: 0.9580 - val_loss: 0.1323 - val_accuracy: 0.9601\n",
            "Epoch 474/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1424 - accuracy: 0.9579 - val_loss: 0.1232 - val_accuracy: 0.9611\n",
            "Epoch 475/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1551 - accuracy: 0.9568 - val_loss: 0.1425 - val_accuracy: 0.9562\n",
            "Epoch 476/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1427 - accuracy: 0.9571 - val_loss: 0.1361 - val_accuracy: 0.9590\n",
            "Epoch 477/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1466 - accuracy: 0.9586 - val_loss: 0.1214 - val_accuracy: 0.9653\n",
            "Epoch 478/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1535 - accuracy: 0.9557 - val_loss: 0.1294 - val_accuracy: 0.9584\n",
            "Epoch 479/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1428 - accuracy: 0.9580 - val_loss: 0.1430 - val_accuracy: 0.9583\n",
            "Epoch 480/1000\n",
            "858/858 [==============================] - 12s 15ms/step - loss: 0.1465 - accuracy: 0.9565 - val_loss: 0.1358 - val_accuracy: 0.9532\n",
            "Epoch 481/1000\n",
            "858/858 [==============================] - 13s 15ms/step - loss: 0.1425 - accuracy: 0.9581 - val_loss: 0.1496 - val_accuracy: 0.9573\n",
            "Epoch 482/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1485 - accuracy: 0.9552 - val_loss: 0.1378 - val_accuracy: 0.9576\n",
            "Epoch 483/1000\n",
            "858/858 [==============================] - 13s 15ms/step - loss: 0.1395 - accuracy: 0.9583 - val_loss: 0.1408 - val_accuracy: 0.9561\n",
            "Epoch 484/1000\n",
            "858/858 [==============================] - 12s 15ms/step - loss: 0.1413 - accuracy: 0.9590 - val_loss: 0.1404 - val_accuracy: 0.9580\n",
            "Epoch 485/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1494 - accuracy: 0.9570 - val_loss: 0.1261 - val_accuracy: 0.9597\n",
            "Epoch 486/1000\n",
            "858/858 [==============================] - 12s 15ms/step - loss: 0.1519 - accuracy: 0.9574 - val_loss: 0.1546 - val_accuracy: 0.9520\n",
            "Epoch 487/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1409 - accuracy: 0.9580 - val_loss: 0.1369 - val_accuracy: 0.9583\n",
            "Epoch 488/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1451 - accuracy: 0.9575 - val_loss: 0.1199 - val_accuracy: 0.9631\n",
            "Epoch 489/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1514 - accuracy: 0.9568 - val_loss: 0.1285 - val_accuracy: 0.9612\n",
            "Epoch 490/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1480 - accuracy: 0.9563 - val_loss: 0.1605 - val_accuracy: 0.9541\n",
            "Epoch 491/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1598 - accuracy: 0.9550 - val_loss: 0.1562 - val_accuracy: 0.9512\n",
            "Epoch 492/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1421 - accuracy: 0.9587 - val_loss: 0.1412 - val_accuracy: 0.9582\n",
            "Epoch 493/1000\n",
            "858/858 [==============================] - 12s 15ms/step - loss: 0.1471 - accuracy: 0.9591 - val_loss: 0.1364 - val_accuracy: 0.9593\n",
            "Epoch 494/1000\n",
            "858/858 [==============================] - 12s 14ms/step - loss: 0.1282 - accuracy: 0.9608 - val_loss: 0.1325 - val_accuracy: 0.9579\n",
            "\n",
            "Akurasi tercapai\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[350.2991943359375, 0.4318181872367859]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Cs8-xPPR-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "18da2447-e754-4503-9c76-be4097a6f5a6"
      },
      "source": [
        "#Kode buat ngeliat history training modelnya\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfbA8e9JAoSOVIEAQSmCIi2gFBUX/AnKgqAioK6IiqK4gm2xIeLuWlZXdMWCK4pYAFERFVdFwQIWQhUQJGAgoRmB0FPn/P54J8OkTyDJZJLzeZ48M/fOO/eeuTM5895z77xXVBVjjDGhLyzYARhjjCkeltCNMaacsIRujDHlhCV0Y4wpJyyhG2NMOWEJ3RhjyglL6OWYiHwqItcVd9tgEpF4EelXAstVEWnlvf+SiDwUSNsTWM/VIvL5icZpTEHEzkMvW0TksN9kNSAVyPRO36yqb5V+VGWHiMQDN6rqomJergKtVTWuuNqKSDTwG1BJVTOKI05jChIR7ABMdqpaI+t+QclLRCIsSZiywj6PZYOVXEKEiPQRkUQR+ZuI7AZeE5FTRORjEUkSkf3e+1F+z1kiIjd6748Ske9E5Clv299EZMAJtm0pIt+IyCERWSQi00TkzXziDiTGR0VkqXd5n4tIfb/HrxWRbSKyV0QeKGD7nCMiu0Uk3G/eEBFZ673fXUS+F5FkEdklIs+LSOV8lvW6iPzdb/oe73N2isjoHG0vFZFVInJQRBJEZLLfw994b5NF5LCI9Mjatn7P7ykiy0XkgPe2Z6Dbpojbua6IvOZ9DftFZL7fY4NFZLX3NWwRkf7e+dnKWyIyOet9FpFob+npBhHZDnzlnf+u93044P2MnOn3/Koi8rT3/Tzg/YxVFZFPROT2HK9nrYgMyeu1mvxZQg8tpwJ1gRbAGNz795p3ujlwDHi+gOefA2wC6gNPAq+KiJxA27eBn4B6wGTg2gLWGUiMI4HrgYZAZeBuABFpD7zoXX4T7/qiyIOq/ggcAf6UY7lve+9nAhO8r6cH0Be4tYC48cbQ3xvPRUBrIGf9/gjwF6AOcCkwVkQu8z52vve2jqrWUNXvcyy7LvAJ8Jz3tf0b+ERE6uV4Dbm2TR4K286zcCW8M73LesYbQ3fgDeAe72s4H4jPb3vk4QKgHXCxd/pT3HZqCKwE/EuETwFdgZ64z/G9gAeYCVyT1UhEOgJNcdvGFIWq2l8Z/cP9Y/Xz3u8DpAGRBbTvBOz3m16CK9kAjALi/B6rBihwalHa4pJFBlDN7/E3gTcDfE15xfig3/StwP+89ycBs/0eq+7dBv3yWfbfgRne+zVxybZFPm3HAx/4TSvQynv/deDv3vszgMf92rXxb5vHcqcCz3jvR3vbRvg9Pgr4znv/WuCnHM//HhhV2LYpynYGGuMS5yl5tHs5K96CPn/e6clZ77PfazutgBjqeNvUxn3hHAM65tEuEtiPOy4BLvG/UNr/b+Xhz3rooSVJVVOyJkSkmoi87N2FPYjbxa/jX3bIYXfWHVU96r1bo4htmwD7/OYBJOQXcIAx7va7f9Qvpib+y1bVI8De/NaF640PFZEqwFBgpapu88bRxluG2O2N45+43nphssUAbMvx+s4RkcXeUscB4JYAl5u17G055m3D9U6z5LdtsilkOzfDvWf783hqM2BLgPHmxbdtRCRcRB73lm0OcrynX9/7F5nXuryf6TnANSISBozA7VGYIrKEHlpynpJ0F9AWOEdVa3F8Fz+/Mkpx2AXUFZFqfvOaFdD+ZGLc5b9s7zrr5ddYVTfgEuIAspdbwJVuNuJ6gbWA+08kBtweir+3gQVAM1WtDbzkt9zCTiHbiSuR+GsO7AggrpwK2s4JuPesTh7PSwBOz2eZR3B7Z1lOzaON/2scCQzGlaVq43rxWTH8AaQUsK6ZwNW4UthRzVGeMoGxhB7aauJ2Y5O99diHS3qF3h5vLDBZRCqLSA/gzyUU4zxgoIj09h7AnELhn9m3gTtwCe3dHHEcBA6LyBnA2ABjmAuMEpH23i+UnPHXxPV+U7z16JF+jyXhSh2n5bPshUAbERkpIhEichXQHvg4wNhyxpHndlbVXbja9gveg6eVRCQr4b8KXC8ifUUkTESaercPwGpguLd9DHBFADGk4vaiquH2grJi8ODKV/8WkSbe3nwP794U3gTuAZ7GeucnzBJ6aJsKVMX1fn4A/ldK670ad2BxL65uPQf3j5yXE45RVdcDt+GS9C5cnTWxkKe9gztQ95Wq/uE3/25csj0EvOKNOZAYPvW+hq+AOO+tv1uBKSJyCFfzn+v33KPAP4Cl4s6uOTfHsvcCA3G96724g4QDc8QdqMK287VAOm4v5XfcMQRU9SfcQddngAPA1xzfa3gI16PeDzxC9j2evLyB20PaAWzwxuHvbuBnYDmwD3iC7DnoDaAD7piMOQH2wyJz0kRkDrBRVUt8D8GUXyLyF2CMqvYOdiyhynropshEpJuInO7dRe+Pq5vOL+x5xuTHW866FZge7FhCmSV0cyJOxZ1Sdxh3DvVYVV0V1IhMyBKRi3HHG/ZQeFnHFMBKLsYYU05YD90YY8qJoA3OVb9+fY2Ojg7W6o0xJiStWLHiD1VtkNdjQUvo0dHRxMbGBmv1xhgTkkQk56+LfazkYowx5YQldGOMKScsoRtjTDlhCd0YY8oJS+jGGFNOWEI3xphywhK6McaUE0E7D90YUzGowu+/Q6NGwY6k9KmCxwPh4bBmDSxaBGecAd26QcOGxb8+66EbU06pwgcfwL59Jb+upCS3vpwyM+Hqq6F5c9iS4+JzCxfC0KGwbFnu5xU0xNTnn8Ott+ZuowoJCXDkyPF5u3fD/rwuvJePl16CP/8ZZs6EVL8R/g8fhu/9rqGkCjNmwKRJ8N572WNJSIAdiYrGbWHEsEx694aUFLjqKrj7bhg4EObNCzymIgnWxUy7du2qxpQVaWmqu3cX/3IzMgpvs3+/anp68axv/37Vu+9W/ewz1YcfVgXVv/zl5Jbp8eRex+efq373nXt9v/yiWqWK6ujRru1bb6nGxbn7o0e7GED1n3/PVFXV2FjVgQPdvPBwj4aFefSBB45vqx9+UG3cWHX+fLddpk5VjY93j/3+u2r9+u6569a5eUcOe/SlvyzVdnV3+dZ10UUenTlTtVYt1ebNjz8/MVH1scdUl87aoulfLNZt8R6Ni3MxTZzonlu7tru9pN1WTbvhFtX16/XyHjsUVJdd/pQefX2ODh+W4VsXqM58LVNTly7X+/r+oJXD07VhxF59mgm+x89rud21e/BXXTptle5YseuE3w8gVvPJq5bQTYXn8aj27696yimq+/bl3ebLL12SUlU9dEg1KUl1717Vp55SfeaZ3F8GqamqkyerVq6s2qKFSyJZEhJUb71VdfVq1cOHVevVU33ySffYiBGq//lP9mXt2KHat697jr+fflK98UbVCy5Qvfxy1UcfVT3zTM2WaBo0UK1UyS3D43GJbdWq3F8gmZmqS5aoPvKI6qfzU1TffFMXXT1DB7SJ00oRmdq2rUfvukt15Vf7tWXjo77lDxvm0f59jk/37pCsoBrVNFPvHr1XQfWhsL9rT77TjmFrdXbbSQqqdWqm62M9PtQ/qKvXM0NB9dKwhfpZ0+u1WZXdCqrNauzTv3X/UkG1da1duuXBGTr4/45opUoeBdV/DVikS+7/n55S5bCCatewFTo1bII+xCNaI8zNO+uURK0ddkBbSLxeX+UtrR1xyBdrOOnZthWoXhfxpqaFR+q0Sne41xc2V1/let/jfcMX61W8o0KmPsbfNJVK2k1+0iYk6pXMUVAdwVtaL8y99g71d+olNb928bFcPVkLevHFonxEs7GEbiq0Q4dc4szPq69k+v5h//53Ny8pSfX8893/3erVqmFhrmf44osu8YObl/W8yEiXYFNSVB98ULVJEzd/6KB07d3boyIumX7xxfEe4JAhqnPnuvtXX62auu+whoV5NCLco6te/lG/vOdTnTh0ozZueDzxLLzo36o//KDTblyhoFo94pj2Pn2Htqn7u693ufD9Y/rvgV/qhDMW6qZ/ztMwydT+UWu1ac1k33JqVU3Vly+aq3rppfrRqHnavuUR32NhZOht/EfDSdcotutt/EcvbRyrYeK20yns1fe5TB9q9bbvOU9wj/biWwXVsUzTmhxQUL0qYp56JtypU4d/79YbfkjPCV+uydRyT7zlFtWHHtIXLpyrlcLc66wiKfps48d8y+5T7QetwjHf9JPcrWexVv/EIj2XZdqceP1u5DT1ZHpUk5NVX3pJt0adp//iLj1Ys4n+0GO8dmm4XRtVTdaLIr/W1Zyt08+aqvddvEKnN52sb3Ctvi9DdV2PG9Vzx3jV++5TveMOfeyGXzUszH15tGuSrI/943iv/PHeH6lOm6b63HP63chpx7fDgwdVjx7Vpd95tGNH1e+/V926VbVbp1T95sV1qp9+qrpokdtVOEGW0E1QrFjhepD+vV6PJ/cuvKpr8/jjqn36qL7yiuqBA6oLFrhkXJCUFNVjx1T37FG9/37VmTNdSWDgQFdyUFX9v/9zPdWvvvIGkJmp8fGqf/yh+ua9a7QmB/SCRr/ogIvStH591e3bVXv3Vl9JoP3px7RePdUmjVzCOatWvD513ny979oEXbvGo+t/ztRG9dK1d88MvftW1zO89Kzf9H8xD6iCbosZqiIevefK37RF9d/1jIjNOrzye1pJ0rRvnVjXsw1fqnGcdvwLAtfrjSBNe7BUl9NV27Feo9iuY3lBhUwdVH2RHqza0PetsjeyiR687Fr3YsH3zXM57/p6iC8xRt9kpJ7PEq1Eqj5Z/wkNI0PbsV7fZKTu5FQ9r7qL6YLzM/Xg1iT3LRcRoas5W29stVjXvLhUdcoU9dSqrQ81fVX7ttmmqUuW6f6vVup3z8aqzpunX49+XW/puEyPbHGlhYQEF1JEhOra7w+7XZK33872Xu7dq/r++66Uo6p64w0ePeMMjyYnq378serYkfs1dvws1f/+V++5eoeKuGT7n/FxuT8YaWmqK1e6XSV/GRmqmza5XZIsBw64lefht9/cns/atapHj6q2aeNKWDk/ww8/7PbC8vpsFzdL6KZQr7ziEqiq6ocfun+snB55RHXkyIKXs3mz6uLFrgQRFeXtYfVRfeEF1U6dVKtWVa1eXbVbN9dzUXX/BOed59o2a5aVSN3thRe6pO3v9dfdP/3KH9O0Qa1jGiaZWrnS8V52Vo21Xq1U/WPtDg0Pd73esDCP/thqpK6LvtSXDED1nMordVtYtH5bo3+23e+Xh3+lp0VsU1Cd3m+Obm56gT4aPkkPtu7iisbgaiHduumL3Ox73s286O40bKh6++2qTZroJXzse3xRn0d19RWPZltXVI19uujGdxRU779ik3Zre0Bf/vsePfr1T+7Nefhh/f6Rz7RJ40ytFJaul562Xo8lp7hvvMREV1MZOFD11FNVhw1T/fprl7TWrNHd6//Q995TzUhJdwnt2DH9I/Y3bXyq22adzkzVQ299qPrcc6orV+rB5EydMUP1yBG/jb5qlavJnIRx41w9PFAeT/7HFr766vh3VkF7X8WtuI51nAxL6Cab335Tvesu1zFRdbuFIqqdO7vpVq1c0v39dzft8Rz/BwL3fH+HDqk++6xqu3bH21Sq5OrH999/fN4556iOH686YYJqzZqu5+zxuPo0uGVkpmfqq6+6+P75Tzf/2mu9QcTG6vc3z/Atr5oc0ebE6yQm6wSe1g2n9NRHOr+vTart11t4UUH1Tp5SUP2IS7UqR/TWGjP14RpPqZCpj3OvvnHm45rxx35XLxk1SmfWHa9T603RxXUuUwVd36SfPtbhTc0gzGWP2Fj3og8edNmpbl3Vpk01/ampelaDXXp63b16aEms6q5dx//7U1J0/tNxCqr9+6b5tlvHju51nHeeK9+88ELe27ekLF7sjh0kJJTO+opTaqora02ZEuxISp8l9HJi8mTVrl1Vr7/elSh27XI93Tlz8m6/ebPqrFm5599+u3vn//Qn10s+6yz11YS3bDmegG+6SbVfP5d869Q53uN++mm3HI9H9bXXVBs1cvPPPdd18ubOdQfp3nzlqOr77+u7d32vnzywVD1vvqV6zz2qo0bpf7q+5mqRzZ7X82qu1Mbhu/VYrYauaz5ypPtPjY7WB6Ncu+9ajFQF7c9CrRe2V+9tMEN71lmnv/13kQt63jzVq67ylRn233CXhodlaqXwDK1dLVXT3/tQr+iRoI0aerR923Q9v9kW9y2V3z5yZqY7jeLwYddm7lzVDRtyt0tP952eceCAy/N5SU9XfeABF2qWt98+XmICd0A0PLxs9AJDQVpa6ZQ4yhpL6OWAx+POhoiKcr3pRx5xNees8sTIka7UMGOGa79/v2rLlu7xefOyL6d5c/fnv8t/663uNivZn9UmxfW0Izz6l7+4mvJPS9O009kZ2qOHRz3vva/39f1BQbVH9wxdOnOz6rffqn7yieo777is37hx9pWA67Y3a6YZLVtp75qrfLOf6fS66l//6gKpWtXN7NdPD3frow3DftcL667SRbfPV8h+xkguGRmuOK7uoCaoDh3qHso6AJm1N1BWZO2hNG6sGh0d7GhMWWcJvRxYt869WzNmuFJFs2aqZ5yhGhPjesaVK6uedpor7X78seqAAe4AVKtWrpQ7c6bLs6tWueX897/ugPu0p49p7H9X6f6vVqqIR6tVzdTKERm6sW4P/ROL9PPaV7ijQr16qVapon/nAVc6YKGrF4e9rJn4ne7h/9e1qzutY+1at+J167IdpEpNVf3xR7eHkZbm92L37FH99Vff5NSpxxfZtGn+veCcnnjCPWf6dDd9+LBqtWpu3vbtxfCmFBP/vaI+fYIdjSnrLKGXYevXuzNBbr/d3c/PtGnu3YqLcz3urAQwfbpLjAcOuDzYuLE72Cei+vyUvbp61lqNiDh+ALDNaekq4tHdE59xXdiICN/CzmKtgmpPvnPfGB99dLzO0rmz6t1368bbn1chU0+pnqKP3bFLPXfe5XYX5sxxvzb54QdXmkhMLLb94WPHVC+7zJUs8jtPPC87d7oyhv8JDGPGuLpxWZKa6t4vcOU0Ywpy0gkd6A9sAuKAiXk83gL4ElgLLAGiClumJXTn4ovdAcQqVVTbt3dndAwd6k6F9c+HV13leqcej0sADRu6c5+Tk9XN+Pln1Xfe0ZUtLtOnmaDb63XyJeq1TS7Wn9tdqaMqv+VKJCw9nqQnTnRd+o8+0jF9Nyuo3nPVtuPd4KSk47+o8Vq7NvBesglM1vfmI48EOxJT1hWU0AsdnEtEwoFpwEVAIrBcRBao6ga/Zk8Bb6jqTBH5E/AYcO1JjUlQDuzYAT/8AFFRbiyLRo0gzG/0nJUr4bPP4J//hDZt4IoroE8f9xyAunXd2A+q8PXX8KcLMpHtiVROTeU/Uxqwb086td9dAI8+Ctu3A9C5bVs6T+kCWzpC+xHQqBEd3n0XPId5uddSam0+k0suqQ43/AH16mWLt9c+mP4l9BzeHGp6Z9av7/78dOhQQhusAouOhsREd2vMCcsv0+vx3ncP4DO/6fuA+3K0WQ80894X4GBhy60IPfRBg7KXlFu3dqekeTzu9pJL3FgTycluXvfurt3IYWl65WVpCqo/XvqIbuzpfnr8cpXb869Vv/GG6jff5ChGF82RI+5YZs7fYpiSd/XV7q385ptgR2LKOk6mhw40BRL8phOBc3K0WQMMBZ4FhgA1RaSequ71byQiY4AxAM2bNy/C107oSUlxQ2WOGOH+tm6FyZPhggugTh1Yu9a1mzIFatcGVHnpzs0883Ayzy0YTHjKYZawhfs/7U292udSmVT6XxYJ//cqVKkCBw+627PPhq5dQeSkY65WDe6886QXY05AVs/ceujmZBTXeOh3A8+LyCjgG2AHkJmzkapOB6YDxMTEaDGtu0xIToYFC+DKK6FqVfj2Wzh61A0deumlrk2vXtC/P5x6Kkx97Ch9Nv+Xszf+BAOTYd06Om/bxhsREXDNNdCuHfcvWs6ELy6F/a6q0vzBJ4P7Ik2JGTEC0tJcec6YEyWuB19AA5EewGRVvdg7fR+Aqj6WT/sawEZVLfCjGRMTo7GxsScUdLBkZrqOsH8d3OOBWbPg3nvdIP433givvAITJsCLL7qxqKtV8zY+fBh97HEkYTt88YV7QsuWUL26G/W+Tx+4/HLfyPcpKdCuHdSqBcuXQ+XKpf6SjTFljIisUNWYvB4LpIe+HGgtIi1xPe/hwMgcK6gP7FNVD67GPuPkQi6bzjkHzj0Xnn/eTe/bB4MGwdKlbv4ll8B//wtdurjB+/uc76HaFx/BV1+5rPzBB8gvv0CLFi6Bf/yxK5fkIzISYmPdrSVzY0xhCk3oqpohIuOAz4BwYIaqrheRKbji/AKgD/CYiCiu5HJbCcYcFPHxsGIFbNwIjz8ONWq45L10qeuRjx7tevCbNrmrqQDcmjoVLrvL1WBSU91pK599Bv36BbzeHCeiGGNMvgKqoavqQmBhjnmT/O7PA0rqokplwpdfutsjR9xlva69Ft5+2/Xab7wiGX7aSNi2bXxV912+PaMJvx48lesSnoA33nDXnso6aFmpUvBehDGmXLOLRAdo0SJo3Nh1tmfOdGWVNWvguT9/AS2ucGedAJGNG3NRmzZclPoxvPUyDB8e5MiNMRWFJfQAeDyuh96/P5x+OjzyiHLdeVsJI5phH10DA8+Hm2+GBg1cTTzCNqsxpvRZ5snDkiWwbRu0auVONfz5Z3dV8379YNCflV/fXM6cuC4MOO1XGr3/OXTsGOyQjTHGEnpOBw7ARRdBRoabfv99ePttJTwc+q19hjpPz+StuLVMHfcIkf+cdPwn8sYYE2RhhTcp3zIz4dix49PffeeS+dtvQ7duMGyYMm+e8FjmvTT5993unPEXXqDBsw9S05K5MaYMqfA99Icecsn711/dud5ff+1uL7sMepzjodtZR+md8QV3jffAA7/nGqjKGGPKigrdQ1eF2bNdvXzBAjdvyRLo3h2qHvqd6LED+O3Yqbx361eE/fspS+bGmDKtQif0X36B335z96dPh0OH3JC2fVpug06d4JtvqDH9GcKef65YBr8yxpiSVKET+iefuNsxY9zQKk8/7WrqF8weCzVrwo8/wk03WTI3xoSEQgfnKillYXCuCy5wvwf6+GM47TQlLU2IDEvlj5qnUX3jCjcsojHGlCEFDc5VYXvo+/a5cVguvRSa7oplQ93z+KrGIGI9Xaj+5MOWzI0xIafCnuXy8ceuvDKo1Qbo25fT69bl9D+3hxqt3Bi4xhgTYipsQn//fYiKUro9eaW7hNA330CzZsEOyxhjTliFLLkcPuxGsR3aZh3yywZ45hlL5saYkFdheuhTp7oRE6+4wl0oKCUFhq6a5AZrGTIk2OEZY8xJqxAJ/fBhmDTJXWMi61TFhtUP03v/Anh6mZ2WaIwpFypEQn/rLfejoaVL3VAsu9f9QYsb+hF+1ZXuChXGGFMOBFRDF5H+IrJJROJEZGIejzcXkcUiskpE1orIJcUf6olRdRdr7tgRevSAjg12cvFLQzhDf4HH8rzOtTHGhKRCe+giEg5MAy4CEoHlIrJAVTf4NXsQmKuqL4pIe9zl6qJLIN4imzvXXVnopZdA9uyGzp1dDeb116Fly2CHZ4wxxSaQkkt3IE5VtwKIyGxgMOCf0BWo5b1fG9hZnEGeqB9/hFGjoGdPd8vjL7sjoitWuGvIGWNMORJIyaUpkOA3neid528ycI2IJOJ657fntSARGSMisSISm5SUdALhFs1tt0GjRjB/PlQJS4eXX3bXkbNkbowph4rrPPQRwOuqGgVcAswSkVzLVtXpqhqjqjENGjQoplXnbds21xEfN85d6pMPPoBdu1yWN8aYciiQhL4D8P/VTZR3nr8bgLkAqvo9EAkEdfDwDz90t4MH4y5JNGWKq5kPGBDMsIwxpsQEktCXA61FpKWIVAaGAwtytNkO9AUQkXa4hF7yNZUCzJ8PZ54JrVsDd98N69e7013Cw4MZljHGlJhCE7qqZgDjgM+AX3Bns6wXkSkiMsjb7C7gJhFZA7wDjNJgjcsL7N3rhma57DLgp5/ghRfgrrvg4ouDFZIxxpS4gH5YpKoLcQc7/edN8ru/AehVvKGduKVL3UiKAwYAs2ZBZCQ8/HCwwzLGmBJVLgfnio93t21Oy3Anog8c6K5AZIwx5Vi5TOjbtkHVqlD/58XuvPMRI4IdkjHGlLhymdDj46FFC5DZ70CtWnBJmRmJwBhjSky5TOjbtkGLpt5yyxVXuBq6McaUc+U2oUenb4YjR+xycsaYCqPcJfQjR+CPP6DF1sXQvj2ce26wQzLGmFJR7hL6tm3utkXid3DTTXbxCmNMhVFuE3o08TB0aFBjMcaY0lTuEnrWOegt6h+1Cz8bYyqUcpfQt22DSqTT+JzmVm4xxlQo5eaaouvWwbXXQuqxTJqzjbDuMcEOyRhjSlW5SejffAOrVwOE8ye2QbduwQ7JGGNKVbkpuezc6UbGfWHIF0xiiiV0Y0yFU2566Dt3QuPGMDZ8OrRMgPpBvb6GMcaUunLTQ9+xA5o0AVatgq5dgx2OMcaUunKT0HfuhCYNM2DrVjj77GCHY4wxpa58JfTIvaAKZ50V7HCMMabUBZTQRaS/iGwSkTgRmZjH48+IyGrv368iklz8oeYvJQX27YMmmYluRocOpbl6Y4wpEwo9KCoi4cA04CIgEVguIgu8l50DQFUn+LW/HehcArHma9cud9vkyK/uyhYtW5bm6o0xpkwIpIfeHYhT1a2qmgbMBgYX0H4E7kLRpWbnTnfbJGktnHmmO3/RGGMqmEASelMgwW860TsvFxFpAbQEvsrn8TEiEisisUlJSUWNNV++hL79B6ufG2MqrOI+KDocmKeqmXk9qKrTVTVGVWMaNGhQbCv1JfS9a61+boypsAJJ6DsA/2ELo7zz8jKcUi63gDsHvXIlD3XZZz10Y0yFFUhCXw60FpGWIlIZl7QX5GwkImcApwDfF2+Ihdu5E5rUOoyAu4U+cqUAABn2SURBVEqRMcZUQIUmdFXNAMYBnwG/AHNVdb2ITBGRQX5NhwOzVVVLJtT87dwJTavsdWe4NGlS2qs3xpgyIaCxXFR1IbAwx7xJOaYnF19YRbNzJ3TQnXD66RBWbn4rZYwxRRLy2U8VEhMhKjUOWrUKdjjGGBM0IT/aYnIyHDkCzVLWQ+vWwQ7HGGOCJuR76IneX/tHZcZbD90YU6GFfEJP8P7kqRkJ1kM3xlRoIZ/QfT10Eq2Hboyp0EK+hp6QAGHioXHl/dA0zxEJjDGmQgj5hJ6YCI2r7CPi9Gg7ZdEYU6GFfAZMSIBmYuUWY4wJ+YSemAhRGdus3GKMqfBCOqGrQkKC0ix9CxTj6I3GGBOKQjqhJyfD0aPiznCxhG6MqeBCOqFnOwfdEroxpoIL6YSe7Rx0S+jGmArOEroxxpQTIZ3Qf//d3Tbkd0voxpgKL6QTelIS1KqSQhXSoF69YIdjjDFBFVBCF5H+IrJJROJEZGI+bYaJyAYRWS8ibxdvmHlLSoIGVQ5B3boQEfI/ejXGmJNSaBYUkXBgGnARkAgsF5EFqrrBr01r4D6gl6ruF5GGJRWwv6QkaBCx38otxhhDYD307kCcqm5V1TRgNjA4R5ubgGmquh9AVX8v3jDzlpQEDSTJEroxxhBYQm8KJPhNJ3rn+WsDtBGRpSLyg4j0L64AC5KUBA0y91hCN8YYim+0xQigNdAHiAK+EZEOqprs30hExgBjAJo3b35SK1T1JvRKOyyhG2MMgfXQdwDN/KajvPP8JQILVDVdVX8DfsUl+GxUdbqqxqhqTIOTTMIHD0J6OjQ4tt0SujHGEFhCXw60FpGWIlIZGA4syNFmPq53jojUx5VgthZjnLkkJbnbBmolF2OMgQASuqpmAOOAz4BfgLmqul5EpojIIG+zz4C9IrIBWAzco6p7Sypo8Evo2EFRY4yBAGvoqroQWJhj3iS/+wrc6f0rFZbQjTEmu5D9pagldGOMya58JPT69YMbjDHGlAEhndCrVUqjGsegTp1gh2OMMUEX0gm9QbUjEB4O1asHOxxjjAm6kB3Ryg3MdRDCaoFIsMMxxpigC+mE3rBSMlStFexQjDGmTAjtkkvYXqhdO9ihGGNMmRCyCT05GU7x7LOEbowxXiGb0FNSoGrGQahlJRdjjIEQTegeD6SlQWTaIeuhG2OMV0gm9NRUdxuZesASujHGeIVkQj92zN1WTdlvCd0YY7xCMqGnpLjbSM8Rq6EbY4xXaCd0UqyHbowxXpbQjTGmnAjJhJ5VQ7eEbowxx4VkQs/qoVflmNXQjTHGK6CELiL9RWSTiMSJyMQ8Hh8lIkkistr7d2Pxh3qclVyMMSa3QgfnEpFwYBpwEZAILBeRBaq6IUfTOao6rgRizMUSujHG5BZID707EKeqW1U1DZgNDC7ZsApmCd0YY3ILJKE3BRL8phO983K6XETWisg8EWmW14JEZIyIxIpIbFLWNeROgO+HRRyDmjVPeDnGGFOeFNdB0Y+AaFU9G/gCmJlXI1WdrqoxqhrT4CQu7OzroVcNg4iQHdLdGGOKVSAJfQfg3+OO8s7zUdW9quodYYX/Al2LJ7y8+RJ6rcoluRpjjAkpgST05UBrEWkpIpWB4cAC/wYi0thvchDwS/GFmJsvodeJLMnVGGNMSCm0XqGqGSIyDvgMCAdmqOp6EZkCxKrqAuCvIjIIyAD2AaNKMObjPyyqXaUkV2OMMSEloAK0qi4EFuaYN8nv/n3AfcUbWv5SUiBCMoioU6O0VmmMMWVeyP5SNFJS7ZRFY4zxE7oJ3c5BN8aYbEIyoR87BpF6DKpXD3YoxhhTZoRkQk9J8f6oqFKlYIdijDFlRsgm9EhNgcp2HroxxmQJ0YSuRFoP3RhjsgnNhH5M3UFR66EbY4xPSCb0Y0e9Cd166MYY4xOSCT3lmNpBUWOMySE0E3rWeehWcjHGGJ/QTujWQzfGGJ+QTOjHjllCN8aYnEIyoaekiquhW8nFGGN8QjahWw/dGGOyC7mErgqpaWF2UNQYY3IIuYTuu1qR9dCNMSYbS+jGGFNOBJTQRaS/iGwSkTgRmVhAu8tFREUkpvhCzC4rodtBUWOMya7QhC4i4cA0YADQHhghIu3zaFcTuAP4sbiD9Gc9dGOMyVsgPfTuQJyqblXVNGA2MDiPdo8CTwApxRhfLr4LRFtCN8aYbAJJ6E2BBL/pRO88HxHpAjRT1U8KWpCIjBGRWBGJTUpKKnKwkKOHbiUXY4zxOemDoiISBvwbuKuwtqo6XVVjVDWmQYMGJ7Q+K7kYY0zeAknoO4BmftNR3nlZagJnAUtEJB44F1hQUgdG7aCoMcbkLZCEvhxoLSItRaQyMBxYkPWgqh5Q1fqqGq2q0cAPwCBVjS2JgK2HbowxeSs0oatqBjAO+Az4BZirqutFZIqIDCrpAHOyg6LGGJO3iEAaqepCYGGOeZPyadvn5MPKnx0UNcaYvIXsL0XtikXGGJNdyCZ0K7kYY0x2IZfQs9XQreRijDE+IZfQe/SAh89f7Eou4eHBDscYY8qMgA6KliW9ekGvnp/DD+EgEuxwjDGmzAi5HjoA6elWPzfGmBxCM6GnpVlCN8aYHEIzoaen2wFRY4zJIXQTuvXQjTEmm9BM6FZyMcaYXEIzoVvJxRhjcgndhG49dGOMySY0E7qVXIwxJpfQTOhWcjHGmFxCM6FbD90YY3IJzYRuPXRjjMkldBO69dCNMSabgBK6iPQXkU0iEiciE/N4/BYR+VlEVovIdyLSvvhD9WMlF2OMyaXQhC4i4cA0YADQHhiRR8J+W1U7qGon4Eng38UeqT8ruRhjTC6B9NC7A3GqulVV04DZwGD/Bqp60G+yOqDFF2IerIdujDG5BDIeelMgwW86ETgnZyMRuQ24E6gM/CmvBYnIGGAMQPPmzYsa63FWQzfGmFyK7QIXqjoNmCYiI4EHgevyaDMdmA4QExNz4r14K7mYciY9PZ3ExERSsi6aayq8yMhIoqKiqFSEzmsgCX0H0MxvOso7Lz+zgRcDjuBEWMnFlDOJiYnUrFmT6OhoxK7EVeGpKnv37iUxMZGWLVsG/LxAaujLgdYi0lJEKgPDgQX+DUSktd/kpcDmgCM4EdZDN+VMSkoK9erVs2RuABAR6tWrV+Q9tkJ76KqaISLjgM+AcGCGqq4XkSlArKouAMaJSD8gHdhPHuWWYmU1dFMOWTI3/k7k8xBQDV1VFwILc8yb5Hf/jiKv+WRYycUYY3IJ3V+KWsnFmGKzd+9eOnXqRKdOnTj11FNp2rSpbzotLa3A58bGxvLXv/610HX07NmzuMI1+Si2s1xKTWYmeDzWQzemGNWrV4/Vq1cDMHnyZGrUqMHdd9/tezwjI4OIiLzTRUxMDDExMYWuY9myZcUTbCnKzMwkPDw82GEELPQSenq6u7WEbsqr8ePBm1yLTadOMHVqkZ4yatQoIiMjWbVqFb169WL48OHccccdpKSkULVqVV577TXatm3LkiVLeOqpp/j444+ZPHky27dvZ+vWrWzfvp3x48f7eu81atTg8OHDLFmyhMmTJ1O/fn3WrVtH165defPNNxERFi5cyJ133kn16tXp1asXW7du5eOPP84WV3x8PNdeey1HjhwB4Pnnn/f1/p944gnefPNNwsLCGDBgAI8//jhxcXHccsstJCUlER4ezrvvvktCQoIvZoBx48YRExPDqFGjiI6O5qqrruKLL77g3nvv5dChQ0yfPp20tDRatWrFrFmzqFatGnv27OGWW25h69atALz44ov873//o27duowfPx6ABx54gIYNG3LHHaVTlQ7dhG4lF2NKXGJiIsuWLSM8PJyDBw/y7bffEhERwaJFi7j//vt57733cj1n48aNLF68mEOHDtG2bVvGjh2b61zqVatWsX79epo0aUKvXr1YunQpMTEx3HzzzXzzzTe0bNmSESNG5BlTw4YN+eKLL4iMjGTz5s2MGDGC2NhYPv30Uz788EN+/PFHqlWrxr59+wC4+uqrmThxIkOGDCElJQWPx0NCQkKey85Sr149Vq5cCbhy1E033QTAgw8+yKuvvsrtt9/OX//6Vy644AI++OADMjMzOXz4ME2aNGHo0KGMHz8ej8fD7Nmz+emnn4q83U9U6CX0rHqe9dBNeVXEnnRJuvLKK30lhwMHDnDdddexefNmRIT0rM5VDpdeeilVqlShSpUqNGzYkD179hAVFZWtTffu3X3zOnXqRHx8PDVq1OC0007znXc9YsQIpk+fnmv56enpjBs3jtWrVxMeHs6vv/4KwKJFi7j++uupVq0aAHXr1uXQoUPs2LGDIUOGAO7HOoG46qqrfPfXrVvHgw8+SHJyMocPH+biiy8G4KuvvuKNN94AIDw8nNq1a1O7dm3q1avHqlWr2LNnD507d6ZevXoBrbM4hF5Ctx66MaWmevXqvvsPPfQQF154IR988AHx8fH06dMnz+dUqVLFdz88PJyMjIwTapOfZ555hkaNGrFmzRo8Hk/ASdpfREQEHo/HN53zfG//1z1q1Cjmz59Px44def3111myZEmBy77xxht5/fXX2b17N6NHjy5ybCcj9M5ysRq6MUFx4MABmjZtCsDrr79e7Mtv27YtW7duJT4+HoA5c+bkG0fjxo0JCwtj1qxZZGZmAnDRRRfx2muvcfToUQD27dtHzZo1iYqKYv78+QCkpqZy9OhRWrRowYYNG0hNTSU5OZkvv/wy37gOHTpE48aNSU9P56233vLN79u3Ly++6H4Un5mZyYEDBwAYMmQI//vf/1i+fLmvN19aQi+hW8nFmKC49957ue++++jcuXORetSBqlq1Ki+88AL9+/ena9eu1KxZk9q1a+dqd+uttzJz5kw6duzIxo0bfb3p/v37M2jQIGJiYujUqRNPPfUUALNmzeK5557j7LPPpmfPnuzevZtmzZoxbNgwzjrrLIYNG0bnzp3zjevRRx/lnHPOoVevXpxxxhm++c8++yyLFy+mQ4cOdO3alQ0bNgBQuXJlLrzwQoYNG1bqZ8iIasmOdJufmJgYjY2NLfoTN26Edu3gnXdg+PDiD8yYIPjll19o165dsMMIusOHD1OjRg1Uldtuu43WrVszYcKEYIdVJB6Phy5duvDuu+/SunXrwp9QgLw+FyKyQlXzPE/UeujGmDLjlVdeoVOnTpx55pkcOHCAm2++OdghFcmGDRto1aoVffv2PelkfiJC96CoJXRjyp0JEyaEXI/cX/v27X3npQdD6PXQ7SwXY4zJU+gldCu5GGNMnkIvoVvJxRhj8hR6CT2rh24lF2OMySb0Err10I0pdhdeeCGfffZZtnlTp05l7Nix+T6nT58+ZJ16fMkll5CcnJyrzeTJk33ng+dn/vz5vnO4ASZNmsSiRYuKEr7xCiihi0h/EdkkInEiMjGPx+8UkQ0islZEvhSRFsUfqpcdFDWm2I0YMYLZs2dnmzd79ux8B8jKaeHChdSpU+eE1p0zoU+ZMoV+/fqd0LKCJevXqsFWaEIXkXBgGjAAaA+MEJH2OZqtAmJU9WxgHvBkcQfqYwdFTTk3fjz06VO8f97RXPN1xRVX8Mknn/guZhEfH8/OnTs577zzGDt2LDExMZx55pk8/PDDeT4/OjqaP/74A4B//OMftGnTht69e7Np0yZfm1deeYVu3brRsWNHLr/8co4ePcqyZctYsGAB99xzD506dWLLli2MGjWKefPmAfDll1/SuXNnOnTowOjRo0lNTfWt7+GHH6ZLly506NCBjRs35oopPj6e8847jy5dutClS5ds47E/8cQTdOjQgY4dOzJxouujxsXF0a9fPzp27EiXLl3YsmULS5YsYeDAgb7njRs3zjfsQXR0NH/72998PyLK6/UB7NmzhyFDhtCxY0c6duzIsmXLmDRpElP9BmF74IEHePbZZwt+kwIQSA+9OxCnqltVNQ2YDQz2b6Cqi1X1qHfyByCKkmIlF2OKXd26denevTuffvop4Hrnw4YNQ0T4xz/+QWxsLGvXruXrr79m7dq1+S5nxYoVzJ49m9WrV7Nw4UKWL1/ue2zo0KEsX76cNWvW0K5dO1599VV69uzJoEGD+Ne//sXq1as5/fTTfe1TUlIYNWoUc+bM4eeffyYjI8M3dgpA/fr1WblyJWPHjs2zrJM1zO7KlSuZM2eOb1x2/2F216xZw7333gu4YXZvu+021qxZw7Jly2jcuHGh2y1rmN3hw4fn+foA3zC7a9asYeXKlZx55pmMHj3aN1Jj1jC711xzTaHrK0wgPyxqCvgPHpwInFNA+xuAT08mqAJZycWUc8EaPTer7DJ48GBmz57tS0hz585l+vTpZGRksGvXLjZs2MDZZ5+d5zK+/fZbhgwZ4hvCdtCgQb7H8huGNj+bNm2iZcuWtGnTBoDrrruOadOm+S4eMXToUAC6du3K+++/n+v5FXGY3WL9paiIXAPEABfk8/gYYAxA8+bNT2wlVnIxpkQMHjyYCRMmsHLlSo4ePUrXrl357bffeOqpp1i+fDmnnHIKo0aNyjXUbKCKOgxtYbKG4M1v+N2KOMxuICWXHUAzv+ko77xsRKQf8AAwSFVT81qQqk5X1RhVjWnQoMGJxGslF2NKSI0aNbjwwgsZPXq072DowYMHqV69OrVr12bPnj2+kkx+zj//fObPn8+xY8c4dOgQH330ke+x/IahrVmzJocOHcq1rLZt2xIfH09cXBzgRk284II8+4p5qojD7AaS0JcDrUWkpYhUBoYDC/wbiEhn4GVcMv+9WCLLj52HbkyJGTFiBGvWrPEl9I4dO9K5c2fOOOMMRo4cSa9evQp8fpcuXbjqqqvo2LEjAwYMoFu3br7H8huGdvjw4fzrX/+ic+fObNmyxTc/MjKS1157jSuvvJIOHToQFhbGLbfcEvBrqYjD7AY0fK6IXAJMBcKBGar6DxGZAsSq6gIRWQR0AHZ5n7JdVQflszjgJIbP/fBDmDUL3n7bkropN2z43IonkGF2izp8bkA1dFVdCCzMMW+S3/3SO2l08GD3Z4wxIWrDhg0MHDiQIUOGFOswu6E3fK4xxoS4khpmN/R++m9MORWsq4eZsulEPg+W0I0pAyIjI9m7d68ldQO4ZL53794in2ppJRdjyoCoqCgSExNJSkoKdiimjIiMjCQqqmg/ureEbkwZUKlSJVq2bBnsMEyIs5KLMcaUE5bQjTGmnLCEbowx5URAvxQtkRWLJAHbTvDp9YE/ijGc4lRWY7O4isbiKrqyGlt5i6uFquY5GFbQEvrJEJHY/H76GmxlNTaLq2gsrqIrq7FVpLis5GKMMeWEJXRjjCknQjWhTw92AAUoq7FZXEVjcRVdWY2twsQVkjV0Y4wxuYVqD90YY0wOltCNMaacCLmELiL9RWSTiMSJyMQgxtFMRBaLyAYRWS8id3jnTxaRHSKy2vt3SRBiixeRn73rj/XOqysiX4jIZu/tKaUcU1u/bbJaRA6KyPhgbS8RmSEiv4vIOr95eW4jcZ7zfubWikiXUo7rXyKy0bvuD0Skjnd+tIgc89t2L5VyXPm+dyJyn3d7bRKR4rlgZtFim+MXV7yIrPbOL5VtVkB+KNnPmKqGzB/uEnhbgNOAysAaoH2QYmkMdPHerwn8CrQHJgN3B3k7xQP1c8x7EpjovT8ReCLI7+NuoEWwthdwPtAFWFfYNgIuAT4FBDgX+LGU4/o/IMJ7/wm/uKL92wVhe+X53nn/D9YAVYCW3v/Z8NKMLcfjTwOTSnObFZAfSvQzFmo99O5AnKpuVdU0YDYQlOvRqeouVV3pvX8I+AVoGoxYAjQYmOm9PxO4LIix9AW2qOqJ/lL4pKnqN8C+HLPz20aDgTfU+QGoIyKNSysuVf1cVTO8kz8ARRtTtYTiKsBgYLaqpqrqb0Ac7n+31GMTEQGGAe+U1PrziSm//FCin7FQS+hNgQS/6UTKQBIVkWigM/Cjd9Y4727TjNIubXgp8LmIrBCRMd55jVQ16yLeu4FGQYgry3Cy/4MFe3tlyW8blaXP3WhcTy5LSxFZJSJfi8h5QYgnr/euLG2v84A9qrrZb16pbrMc+aFEP2OhltDLHBGpAbwHjFfVg8CLwOlAJ2AXbnevtPVW1S7AAOA2ETnf/0F1+3hBOV9VRCoDg4B3vbPKwvbKJZjbKD8i8gCQAbzlnbULaK6qnYE7gbdFpFYphlQm37scRpC981Cq2yyP/OBTEp+xUEvoO4BmftNR3nlBISKVcG/WW6r6PoCq7lHVTFX1AK9Qgrua+VHVHd7b34EPvDHsydqF897+XtpxeQ0AVqrqHm+MQd9efvLbRkH/3InIKGAgcLU3EeAtaez13l+Bq1W3Ka2YCnjvgr69AEQkAhgKzMmaV5rbLK/8QAl/xkItoS8HWotIS29PbziwIBiBeGtzrwK/qOq//eb7172GAOtyPreE46ouIjWz7uMOqK3DbafrvM2uAz4szbj8ZOsxBXt75ZDfNloA/MV7JsK5wAG/3eYSJyL9gXuBQap61G9+AxEJ994/DWgNFP+l5POPK7/3bgEwXESqiEhLb1w/lVZcfvoBG1U1MWtGaW2z/PIDJf0ZK+mjvcX9hzsa/Cvum/WBIMbRG7e7tBZY7f27BJgF/OydvwBoXMpxnYY7w2ANsD5rGwH1gC+BzcAioG4Qtll1YC9Q229eULYX7ktlF5COq1fekN82wp15MM37mfsZiCnluOJw9dWsz9lL3raXe9/j1cBK4M+lHFe+7x3wgHd7bQIGlPZ76Z3/OnBLjralss0KyA8l+hmzn/4bY0w5EWolF2OMMfmwhG6MMeWEJXRjjCknLKEbY0w5YQndGGPKCUvoxhhTTlhCN8aYcuL/ARswMCp6rio+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfrG8e+TBAi9g0KorhSRjmBDwbYqrFjQn8gqqGtby4K9rOgqrrqWVdaKiqyKYltRFMUuKmsBpBdFhDV0EEJLgCT37493EpKQQIAkkxmez3XlmpkzZ8555szkPu95TxmThHPOudiXEO0CnHPOlQwPdOecixMe6M45Fyc80J1zLk54oDvnXJzwQHfOuTjhge4KZWbvm9mgkh43msxssZmdUArTlZn9LnL/KTO7vTjj7sV8BprZh3tb5y6m28vMUkt6uq7sJUW7AFdyzGxTnodVgK1AVuTxZZLGFHdakk4pjXHjnaTLS2I6ZtYc+AWoICkzMu0xQLE/Q7f/8UCPI5Kq5dw3s8XAnyR9XHA8M0vKCQnnXPzwLpf9QM4mtZndZGYrgOfNrLaZvWtmq81sXeR+Sp7XfG5mf4rcH2xmX5nZg5FxfzGzU/Zy3BZmNsnMNprZx2b2uJm9VETdxanxbjP7OjK9D82sXp7nzzezJWa21sxu28Xy6WFmK8wsMc+wM8xsZuR+dzP7r5mtN7PlZvaYmVUsYlqjzWx4nsc3RF6zzMwuKjBuHzP7wcw2mNmvZnZnnqcnRW7Xm9kmMzsiZ9nmef2RZva9maVFbo8s7rLZFTNrG3n9ejObY2an5XnuVDObG5nmUjO7PjK8XuTzWW9mv5nZl2bm+VLGfIHvPw4A6gDNgEsJn/3zkcdNgXTgsV28vgewAKgH/AN4zsxsL8Z9GfgOqAvcCZy/i3kWp8bzgAuBBkBFICdgDgGejEy/UWR+KRRC0rfAZuC4AtN9OXI/CxgaeT9HAMcDf95F3URqODlSz4nAwUDB/vvNwAVALaAPcIWZnR557pjIbS1J1ST9t8C06wDvASMi7+1h4D0zq1vgPey0bHZTcwVgPPBh5HVXA2PMrHVklOcI3XfVgUOBTyPDrwNSgfpAQ+BWwK8rUsY80Pcf2cAdkrZKSpe0VtKbkrZI2gjcAxy7i9cvkfSMpCzg38CBhH/cYo9rZk2Bw4BhkrZJ+gp4p6gZFrPG5yX9KCkdeA3oFBneH3hX0iRJW4HbI8ugKK8AAwDMrDpwamQYkqZK+kZSpqTFwNOF1FGYcyL1zZa0mbACy/v+Ppc0S1K2pJmR+RVnuhBWAD9JejFS1yvAfOAPecYpatnsyuFANeC+yGf0KfAukWUDbAcOMbMaktZJmpZn+IFAM0nbJX0pv1BUmfNA33+slpSR88DMqpjZ05EuiQ2ETfxaebsdCliRc0fSlsjdans4biPgtzzDAH4tquBi1rgiz/0teWpqlHfakUBdW9S8CK3xM82sEnAmME3SkkgdrSLdCSsidfyd0FrfnXw1AEsKvL8eZvZZpEspDbi8mNPNmfaSAsOWAI3zPC5q2ey2Zkl5V355p3sWYWW3xMy+MLMjIsMfABYCH5rZIjO7uXhvw5UkD/T9R8HW0nVAa6CHpBrs2MQvqhulJCwH6phZlTzDmuxi/H2pcXneaUfmWbeokSXNJQTXKeTvboHQdTMfODhSx617UwOh2yivlwlbKE0k1QSeyjPd3bVulxG6ovJqCiwtRl27m26TAv3fudOV9L2kfoTumHGElj+SNkq6TlJL4DTgWjM7fh9rcXvIA33/VZ3QJ70+0h97R2nPMNLinQLcaWYVI627P+ziJftS4xtAXzM7OrID8y52/31/GfgLYcXxeoE6NgCbzKwNcEUxa3gNGGxmh0RWKAXrr07YYskws+6EFUmO1YQuopZFTHsC0MrMzjOzJDP7P+AQQvfIvviW0Jq/0cwqmFkvwmc0NvKZDTSzmpK2E5ZJNoCZ9TWz30X2laQR9jvsqovLlQIP9P3XI0BlYA3wDfBBGc13IGHH4lpgOPAq4Xj5wux1jZLmAFcSQno5sI6w025XcvqwP5W0Js/w6wlhuxF4JlJzcWp4P/IePiV0R3xaYJQ/A3eZ2UZgGJHWbuS1Wwj7DL6OHDlyeIFprwX6ErZi1gI3An0L1L3HJG0jBPgphOX+BHCBpPmRUc4HFke6ni4nfJ4Qdvp+DGwC/gs8IemzfanF7Tnz/RYumszsVWC+pFLfQnAu3nkL3ZUpMzvMzA4ys4TIYX39CH2xzrl95GeKurJ2APAfwg7KVOAKST9EtyTn4oN3uTjnXJzwLhfnnIsTUetyqVevnpo3bx6t2TvnXEyaOnXqGkn1C3suaoHevHlzpkyZEq3ZO+dcTDKzgmcI5/IuF+ecixMe6M45Fyc80J1zLk74cejOxbnt27eTmppKRkbG7kd25UZycjIpKSlUqFCh2K/xQHcuzqWmplK9enWaN29O0b9J4soTSaxdu5bU1FRatGhR7Nd5l4tzcS4jI4O6det6mMcQM6Nu3bp7vFXlge7cfsDDPPbszWcWe4E+ezbcfjusXh3tSpxzrlyJvUCfNw+GD4eVK6NdiXOuGNauXUunTp3o1KkTBxxwAI0bN859vG3btl2+dsqUKVxzzTW7nceRRx5ZIrV+/vnn9O3bt0SmFQ2xt1M0Z4/v9u3RrcM5Vyx169Zl+vTpANx5551Uq1aN66+/Pvf5zMxMkpIKj6Ju3brRrVu33c5j8uTJJVNsjIu9FroHunMxb/DgwVx++eX06NGDG2+8ke+++44jjjiCzp07c+SRR7JgwQIgf4v5zjvv5KKLLqJXr160bNmSESNG5E6vWrVqueP36tWL/v3706ZNGwYOHEjOFWUnTJhAmzZt6Nq1K9dcc80etcRfeeUV2rdvz6GHHspNN90EQFZWFoMHD+bQQw+lffv2/POf/wRgxIgRHHLIIXTo0IFzzz133xfWHvAWunP7kyFDINJaLjGdOsEjj+zxy1JTU5k8eTKJiYls2LCBL7/8kqSkJD7++GNuvfVW3nzzzZ1eM3/+fD777DM2btxI69atueKKK3Y6TvuHH35gzpw5NGrUiKOOOoqvv/6abt26cdlllzFp0iRatGjBgAEDil3nsmXLuOmmm5g6dSq1a9fmpJNOYty4cTRp0oSlS5cye/ZsANavXw/Afffdxy+//EKlSpVyh5UVb6E756Li7LPPJjExEYC0tDTOPvtsDj30UIYOHcqcOXMKfU2fPn2oVKkS9erVo0GDBqwsZF9a9+7dSUlJISEhgU6dOrF48WLmz59Py5Ytc4/p3pNA//777+nVqxf169cnKSmJgQMHMmnSJFq2bMmiRYu4+uqr+eCDD6hRowYAHTp0YODAgbz00ktFdiWVlthtoWdmRrcO52LRXrSkS0vVqlVz799+++307t2bt956i8WLF9OrV69CX1OpUqXc+4mJiWQWkgPFGack1K5dmxkzZjBx4kSeeuopXnvtNUaNGsV7773HpEmTGD9+PPfccw+zZs0qs2DfbQvdzJqY2WdmNtfM5pjZXwoZp5eZpZnZ9MjfsNIpF8hZMN5Cdy5upKWl0bhxYwBGjx5d4tNv3bo1ixYtYvHixQC8+uqrxX5t9+7d+eKLL1izZg1ZWVm88sorHHvssaxZs4bs7GzOOusshg8fzrRp08jOzubXX3+ld+/e3H///aSlpbFp06YSfz9FKc5qIxO4TtI0M6sOTDWzjyTNLTDel5JK/3gf73JxLu7ceOONDBo0iOHDh9OnT58Sn37lypV54oknOPnkk6latSqHHXZYkeN+8sknpKSk5D5+/fXXue++++jduzeS6NOnD/369WPGjBlceOGFZGdnA3DvvfeSlZXFH//4R9LS0pDENddcQ61atUr8/RRlj39T1MzeBh6T9FGeYb2A6/ck0Lt166a9+oGLmTOhY0d44w0466w9f71z+5l58+bRtm3baJcRdZs2baJatWpI4sorr+Tggw9m6NCh0S5rlwr77MxsqqRCj+Xco52iZtYc6Ax8W8jTR5jZDDN738zaFfH6S81siplNWb23Z3p6C905txeeeeYZOnXqRLt27UhLS+Oyyy6Ldkklrtg99WZWDXgTGCJpQ4GnpwHNJG0ys1OBccDBBachaSQwEkILfa8q9kB3zu2FoUOHlvsW+b4qVgvdzCoQwnyMpP8UfF7SBkmbIvcnABXMrF6JVprDA9055wpVnKNcDHgOmCfp4SLGOSAyHmbWPTLdtSVZaC4PdOecK1RxulyOAs4HZplZzilmtwJNASQ9BfQHrjCzTCAdOFd7ure1uDzQnXOuULsNdElfAbu8MK+kx4DHSqqoXfJAd865Qvmp/865UtW7d28mTpyYb9gjjzzCFVdcUeRrevXqRc5hzaeeemqh10S58847efDBB3c573HjxjF37o5TZoYNG8bHH3+8J+UXqrxeZjd2A91P/XcuJgwYMICxY8fmGzZ27NhiX09lwoQJe31yTsFAv+uuuzjhhBP2alqxIPYC3U/9dy6m9O/fn/feey/3xywWL17MsmXL6NmzJ1dccQXdunWjXbt23HHHHYW+vnnz5qxZswaAe+65h1atWnH00UfnXmIXwjHmhx12GB07duSss85iy5YtTJ48mXfeeYcbbriBTp068fPPPzN48GDeeOMNIJwR2rlzZ9q3b89FF13E1q1bc+d3xx130KVLF9q3b8/8+fOL/V6jfZnd2Ls4V0JC+PNAd26PRePquXXq1KF79+68//779OvXj7Fjx3LOOedgZtxzzz3UqVOHrKwsjj/+eGbOnEmHDh0Knc7UqVMZO3Ys06dPJzMzky5dutC1a1cAzjzzTC655BIA/vrXv/Lcc89x9dVXc9ppp9G3b1/69++fb1oZGRkMHjyYTz75hFatWnHBBRfw5JNPMmTIEADq1avHtGnTeOKJJ3jwwQd59tlnd7scysNldmOvhQ6h28UD3bmYkbfbJW93y2uvvUaXLl3o3Lkzc+bMydc9UtCXX37JGWecQZUqVahRowannXZa7nOzZ8+mZ8+etG/fnjFjxhR5+d0cCxYsoEWLFrRq1QqAQYMGMWnSpNznzzzzTAC6du2ae0Gv3SkPl9mNvRY6eKA7t5eidfXcfv36MXToUKZNm8aWLVvo2rUrv/zyCw8++CDff/89tWvXZvDgwWRkZOzV9AcPHsy4cePo2LEjo0eP5vPPP9+nenMuwVsSl98ty8vsegvdOVfqqlWrRu/evbnoootyW+cbNmygatWq1KxZk5UrV/L+++/vchrHHHMM48aNIz09nY0bNzJ+/Pjc5zZu3MiBBx7I9u3bGTNmTO7w6tWrs3Hjxp2m1bp1axYvXszChQsBePHFFzn22GP36T2Wh8vsegvdOVcmBgwYwBlnnJHb9dKxY0c6d+5MmzZtaNKkCUcdddQuX9+lSxf+7//+j44dO9KgQYN8l8C9++676dGjB/Xr16dHjx65IX7uuedyySWXMGLEiNydoQDJyck8//zznH322WRmZnLYYYdx+eWX79H7KY+X2d3jy+eWlL2+fC5ASgr8/vfw3HMlW5Rzccgvnxu7SvXyueWGt9Cdc24nHujOORcnPNCd2w9Eq2vV7b29+cxiN9D91H/niiU5OZm1a9d6qMcQSaxdu5bk5OQ9ep0f5eJcnEtJSSE1NZW9/tlHFxXJycn5jqIpDg905+JchQoVaNGiRbTLcGUgNrtckpI80J1zroDYDHRvoTvn3E480J1zLk54oDvnXJzwQHfOuTjhge6cc3HCA9055+KEB7pzzsWJ2A10P/XfOefyid1A9xa6c87l44HunHNxwgPdOefihAe6c87FidgM9JyLc/n1nZ1zLldsBnqFCuE2Kyu6dTjnXDkS24Hu3S7OOZdrt4FuZk3M7DMzm2tmc8zsL4WMY2Y2wswWmtlMM+tSOuVGeKA759xOivOLRZnAdZKmmVl1YKqZfSRpbp5xTgEOjvz1AJ6M3JYOD3TnnNvJblvokpZLmha5vxGYBzQuMFo/4AUF3wC1zOzAEq82hwe6c87tZI/60M2sOdAZ+LbAU42BX/M8TmXn0MfMLjWzKWY2ZZ9+sDYn0P30f+ecy1XsQDezasCbwBBJG/ZmZpJGSuomqVv9+vX3ZhKBt9Cdc24nxQp0M6tACPMxkv5TyChLgSZ5HqdEhpUOD3TnnNtJcY5yMeA5YJ6kh4sY7R3ggsjRLocDaZKWl2Cd+XmgO+fcTopzlMtRwPnALDObHhl2K9AUQNJTwATgVGAhsAW4sORLzcMD3TnndrLbQJf0FWC7GUfAlSVV1G55oDvn3E5i7kzRqVPhz0+1ZwUNPdCdcy6PmAv0xYvhyXebsooGHujOOZdHzAV65crhNp3KHujOOZdHzAV6cnK4zSDZA9055/KIuUD3FrpzzhUutgPdT/13zrlcMRfo3uXinHOFi7lA9y4X55wrXMwFurfQnXOucDEX6N5Cd865wsVsoHsL3Tnn8ou5QE9KgoQEeQvdOecKiLlANwutdA9055zLL+YCHcKOUe9ycc65/GIy0L2F7pxzO4vRQDcyPNCdcy6fmAz05GRIT6jip/4751weMRnolStDulXxFrpzzuURk4GenAwZ5l0uzjmXV0wGetgp6i1055zLK2YD3Q9bdM65/GIy0JOT/bBF55wrKCYDPbTQK3mgO+dcHjEZ6MnJkC7vcnHOubxiMtArV/ZAd865gmI20DOyK0J6erRLcc65ciMmAz05GbJIYvu6TdEuxTnnyo2YDPTcH7lI2xrdQpxzrhyJyUDP+V3R9A3eh+6cczliMtBzW+gbPdCdcy5HTAZ6bgt9cxZkZ0e3GOecKyd2G+hmNsrMVpnZ7CKe72VmaWY2PfI3rOTLzC+nhZ5OZdi4sbRn55xzMaE4LfTRwMm7GedLSZ0if3fte1m7ltvlQjJs2FDas3POuZiw20CXNAn4rQxqKbbcLhcqe6A751xESfWhH2FmM8zsfTNrV9RIZnapmU0xsymrV6/e65l5C90553ZWEoE+DWgmqSPwL2BcUSNKGimpm6Ru9evX3+sZ5muhp6Xt9XSccy6e7HOgS9ogaVPk/gSggpnV2+fKdiHfTlFvoTvnHFACgW5mB5iZRe53j0xz7b5Od1e8y8U553aWtLsRzOwVoBdQz8xSgTuACgCSngL6A1eYWSaQDpwrSaVWMb5T1DnnCrPbQJc0YDfPPwY8VmIVFYO30J1zbmexfaZoxVq+U9Q55yJiMtCTksJfRsUa3kJ3zrmI3Xa5lFeVK0N6hZoe6M45FxGzgZ6cDOlW3QPdOeciYrLLBSI/Q5dUzfvQnXMuImYDPTkZ0hOqegvdOeciYjbQK1eGLeaB7pxzOWI20OvWhd+y/CgX55zLEbOB3qABrMqoGX7gIisr2uU451zUxWyg168Pq7ZUDQ82bYpuMc45Vw7EbKA3aABpGclso4J3uzjnHDEe6ACrqe+B7pxzxEGgr6IBrF8f3WKcc64ciI9A34efs3POuXgRH4G+alV0i3HOuXLAA9055+JEzAZ69epQsSKsqtTUA90554jhQDeLnFxUKQVWrox2Oc45F3UxG+gQAn114oHeQnfOOeIg0FdR3wPdOeeIh0DPrONdLs45RzwEenoNtHYtZGZGuxznnIuqmA/09MwKbKYqrFkT7XKccy6qYjrQ69cPt34sunPOxXig55xctIIDvB/dObffi+lAb9Ik3P5KE2+hO+f2ezEd6M2ahdslNPNAd87t92I60GvUgFq1xJKEFh7ozrn9XkwHOkCzZsaSCgd7H7pzbr8X84HevDkssebeQnfO7fdiPtCbNYMlmY3Q4iXRLsU556Jqt4FuZqPMbJWZzS7ieTOzEWa20MxmmlmXki+zaM2awcbMKqxfuAays8ty1s45V64Up4U+Gjh5F8+fAhwc+bsUeHLfyyq+3CNdtjaEX38ty1k751y5sttAlzQJ+G0Xo/QDXlDwDVDLzA4sqQJ3J9+hiz/+WFazdc65cqck+tAbA3mbxqmRYTsxs0vNbIqZTVldQj/s7IHunHNBme4UlTRSUjdJ3ernXIhlH9WrB5UrKxy6uGBBiUzTOediUUkE+lKgSZ7HKZFhZcIscix61bbeQnfO7ddKItDfAS6IHO1yOJAmaXkJTLfYmjUjnC3qge6c248l7W4EM3sF6AXUM7NU4A6gAoCkp4AJwKnAQmALcGFpFVuUlBSY+XUDWLwYMjIgObmsS3DOuajbbaBLGrCb5wVcWWIV7YXGjWHF5mpsVyIVfv4Z2rWLZjnOORcVMX+mKIQWumThuuhz50a7HOeci4q4CXSA1IRmMGNGdItxzrkoiYtAbxw56j21cQ+YPj26xTjnXJTERaDnttDrd/YWunNuvxUXgV67NlSuDKnV2kBqKqxZE+2SnHOuzMVFoJuFVvrShEhT3Vvpzrn9UFwEOoR+9NQtdcMD70d3zu2H4ibQU1IgdWWFkOzeQnfO7YfiKtCXLoXsjp1hypRol+Occ2UurgI9MxNmHnQGy+et898Ydc7td+Im0HOORe/6+IWczjiYNCm6BTnnXBmLm0Dv2BGqVIEGDWAuh6DPv4h2Sc45V6biJtBbtIDNm+Gmm4xNVOe3T36IdknOOVem4ibQczRvHm4Xz0/3E4ycc/uV+A10msMnn0SzFOecK1PxG+g1OsJLL0W1FuecK0txF+i1akHNmrD4d8fD++/74YvOuf1G3AU6hFb6khrtISsLXn452uU451yZiNtAX7y2BnTtCv/+d7TLcc65MhG/gb4YdMGgcKGumTOjXZJzzpW6uA30jRth3ckDICkJXngh2iU551ypi9tAB1i8qR706QNjxoQLvTjnXByL60CfPx8YNAhWrIAPPohmSc45V+riMtAPPRQaNoQ33iC00Js1gzvvhOzsaJfmnHOlJi4DPSkJzjsP3n0XfttUEe6+G6ZOhddei3ZpzjlXauIy0AHOPx+2b4dXXyWke4cOcMstYW+pc87FobgN9E6doF07ePpp2JqZCI8/Dv/7HwwZEu3SnHOuVMRtoJvBHXeEnxcdPBiyjzwabr4ZRo2CF1+MdnnOOVfi4jbQAc4+G+67D8aOhcceI+wY7dULLrwQ3nwzytU551zJiutAB7jxRjjuOLjnHti8rQJpL41H3XuEfvVZs6JdnnPOlZi4D3SzEOarVsHJJ0O95tW4vuNH4bKMf/wjbN0a7RKdc65EFCvQzexkM1tgZgvN7OZCnh9sZqvNbHrk708lX+reO/xw+MMf4KuvoFUrePipKky4Yny4xsstt0S7POecKxG7DXQzSwQeB04BDgEGmNkhhYz6qqROkb9nS7jOffbiiyG/p04NRzBe+GR3tlx+Lfzzn5FjG51zLrYVp4XeHVgoaZGkbcBYoF/pllXyataE9u0hORkefTR0wbza5X448ki4+GKYMyfaJTrn3D4pTqA3Bn7N8zg1Mqygs8xsppm9YWZNCpuQmV1qZlPMbMrq1av3otySceyx0LYtPPlMErz+OlSvDmecEY5T3749anU559y+KKmdouOB5pI6AB8Bhf6qhKSRkrpJ6la/fv0SmvWeM4M//xm+/x6mLGsEr73Gsz/3ZmKzS6BxY/jxx6jV5pxze6s4gb4UyNviTokMyyVpraScw0WeBbqWTHml5/zzoWpVeOQRWNCgJ5dkP83JTOTmDbeiCy8KP1/nnHMxpDiB/j1wsJm1MLOKwLnAO3lHMLMD8zw8DZhXciWWjpo14bLLwklHN94IFSvCuefC/VuHMH3y5tCvPn16tMt0zrli222gS8oErgImEoL6NUlzzOwuMzstMto1ZjbHzGYA1wCDS6vgkjR0KCQkwDvvwIAB8PDDYfhHR94Rfly6c+dwqqkU3UKdc64YTFEKq27dumnKlClRmXdeF18cLu8ybVrI7w4doEED+Pj1dXDllfDKK3DppeHwxipVol2uc24/Z2ZTJXUr7Lm4P1N0dx58ECZMCGEOcNJJ8OWXsKVSbXjpJT7+v2d4e+QKsjp1hdtug+++i27BzjlXhP0+0GvXhlNO2fH4xBNh2zZ46y24+i8JnPjqnzidt2n7vw9Yed/z0KMHXHIJpKVFr2jnnCvEfh/oBfXsCZUqhcu8PPYYXHttOMv0p63NePOBRXDDDSwY9TVpnXvB5Mnev+6cKzc80AuoUiUcyjhsGPzwAzz0EAwcCC1awMQvkvmizz9okz2XWr/8wMVHzYODDw6nnm7Zkn9CP/3kJyk558pUUrQLKI8uvzz/Y7NwpcYXXoDExNBNc1KvbYx662JuqfURvxsyJBz72LYtnH46rF0bmvennx6uu57g603nXOnzpCmm3/8eNm8Ofevnnw8PP1aRhAQYddJYmDQp/LRd7dpw110hzI87DsaNC8dDDh7sP6jhnCt13kIvpuOOg6QkyMwM+0QbNYI+feD556Fhw55Y455c/Sm8+PBqnnqxKi0OqMzwP95Bi5fuDmcx/fvfoe+mZ8/Qf9O2LTQp9JI3zjm3V/b749D3RJ8+oZX++efh8TvvQL8815289NJwTHuLFpCaGnpcXh6VEfpp/vrX0Nee84MaZjBoUDi7qV27ME4hRo+GZcvg1ltL9a0552LEro5D90DfAxkZ4aCWypXD4+zs0ELv0iX0tIwbBwcdFK65fsst4bmVK6FGDXa8YNkyWLQIxo+HESPCMZLJyWFvbJMmcPTRoSV/+OFs3mKkpIQjJOfMCY16F5+mTQuNgylToGHDaFfjyjM/saiEJCfvCHMI+zovvjiclPTSS3DDDaHVXrMmXHBBWAG88UYY96ef4J57E+h+Zgr9RxzDxBMeYOv8X8IxkVddFfraGzQgfdQr4RrtycmMqXsN69dDomVxzzkzYF7kEjkZGWEP7SOPhE0GF/O+/jps1f3wQ7QrcTFNUlT+unbtqniWnS21aiU1by516CCFtr3Uo4dUt264X7mydO+9O17z/PNShQrZeumSz5R9w41qVztVnRNn6Hr+oQQy9WNiG+mII6Tq1XdMsGlT6Z57pG+/lTIzS6RuV/auvz58nI89Fu1KXHkHTFERueo7RUuJWWh433RT6FN/+GHo3z/0qmRkwNcdCxIAABLXSURBVIcfwsiRoWvm0EPDZnY4XNK4+IVejO7Ziznr4PlnG3Ly0c14+JAEXuj0EHczHAYOZFrHC5n6cy0umXR+uCTBbbeFH76+8MKwefD552ETokWL0Ipfvx4yMvgmoxN12h1Iq+Ob7HRtmtRUaNMmdB2dcEIUFtp+bMmScLtoUXTrcDGuqKQv7b94b6Hn2FWLNz1d6txZSkgIrbOUFGnuXKllS6laNemBB6SsrDDuccdJrVvvmF737uE1M2ZIWrlSGjtWOu88rbADdDN/14lM1EucJ4FW0EAfcoKG8pBAOoxvw0w7dZKuukp68UXpxRf17JnvCaQ/954rrVsXZpSZKf38cyg2Yt48adGiyIMtW3YUWc5kZkr//Kf02287hmVlSRkZ0aupKD16hM/z9NOjXYkr79hFC90DPcoWLZL+9CfpoYekJUvCsHXrpLVr84/35JPh05o5U/rvf3f0uAwYsGOcrCzpmG6blJSQpXp1MlWjepa+fW6W6tTcnjt+2xZbBFLqkAek44+XqlTJndgfeSGMwxypfn3pgw+kww8Pz5tJ/fpp3Zj3VLlimF6HlDVaWr11SKO5c0O3z48/lkq/zcyZ0rBh0uWXFz+QP/oolH7//TuG3XJL6KXatq3ES9wnBxwQam3fPtqVuPLOAz0OrFgRGtW33iqdc45Us6Z0xRVh2IMPSv/6l3TddeETHTVKWrBAqlBBSkqSatSQJkwIWTt7dhjnySfDeNdfm6lvX/lZ2Qt+VONGWUpMzBZIP6cco4t5Rp9VOFG67z7phhukmjX1HBcKpJu4V9XYoE5VFmhD9UY71jAQ0qlrV+mCC8KWw7p1Ulqa9Nln0uLF0qZN0sKF0urVUlaW0tLyvNENG8I+gQEDpNRUSWGlV7nyjsmPHVu8ZXbDDWH8E04Ij7dtk+rVC8PefbdEP559kp4eakpIkKpW9f0Ybtc80ONEr147Qu3aa6Vly0IA5M3SP/xhRyDcemsY9uabO6aRnS0ddFDovklM3PG6m28OtxddFG67dNgWdtxWytQDD0jnny9Nem+Dju/6mw5qulXZn36m9//2rRITs9W9Y7oW3jRSE277SgvvGhOC/OSTpTp1JNC4hNP1asK5+QsFzaO1zuJ1GVm6r9rdYQ9yxYrh+QoVpHr1lN29h06t8pmqVUjXz/e9pqYN0nVixxXSyJHS00+HFUBeS5ZIH34opaerY8cwqUqVpM2bpbff3rGxkXfLJtp++inU1bVruF2xItoVufLMAz1OzJ4t/f3voTWe08X9228hAJYvlyZPDo3fHFlZofu7oKFDlXuAzJIloX8+J2dnzQotepBOOUU65JAdrcdatcLtX/+6Y1pvvZV/pVKlivT44yFv3307U+Pum6sEyxJI91wwT6vuH6VNf3tQH13/gWokZ6hmpXR1bLBUFRO2aU7fG8LhHt98I82dq+zjjtfDBz0mkB6qdIsEupNhMrJ0O39TW+ZoZr3e0mWXSf37h50QkUJWND1MIB3TeKFA+qD77Tqr7meqX3mD/tRlqqokbNHGQVdKv/wS3simTdKzz0rnnRemN2yY1L27tl92pWZ9uzmsPEaOlLZu3fHm09Kkhx8O/WVZWdqetllp85YW+fmNHh32P+R4882wzhszJpSdc6TL5Ml7/t3YGytXhi6oVavKZn4l7YEHpDfeiHYVZc8D3eUzZUoI7U8/DY9//VWqXVtq2DC04Pv2DQ3ln38OK47vvgs9JPXrh2/MnDn5pzd7dsi/t9+Wjj56p4a4unaVzt25ga527aT//S+skOrWlRo1ClshbduGlU2nTmG8vn2l7RmZ0k8/ackrX8ssdAslJmbrd8n/04xax2hEvb+pW+2Fql5pq+pUy9Cp1b4QSJOST1RFMtSz6lRVsG0akvCovuQogXRVwuPamFwv9D1F9kpmNGyqv1e6U0fwtSYdNFhn86pAmsDJygbNOuAEZf9liHTxxaHfK/Jmsg8/Qn0qTNSBLNXqZpE3PGxY6K464wzNatNfIHU+YKkyh9+r7LffUaeDN4ZDWVuuEkjvDZ8mCME/caL0wYurtPL1L6TXXgsrlIkTtWVztrKWrdixwyXHxo3SSy9Jd90l/fBD4f02a9bk7pzJypJOPDGUf/QRmcqY/0tI9s2bS63P5+23pddfL/74mZm5vW47Wb48bGEecED+dWxpy8yM/jEAHuhuJwX/Z7/5Rvr443B/4ULpiy92fs306aHvfVe2bZO+/DKsDN54IzR2ly8P/whvvSWNGBF2Uj7++I6tDEn65JOwRXD00dIZZ4SG8hFHhHEL/gMNHx72G3zxRf5uo86dpb/8JXQ7gVS3brayssK+35xzAJb9uFFZvy7VoEFhWO3ENJ3PvzW/wqHa8tKb6tw5rCxq1czKnW61hE067Hdrde9FCwTSsfaFHq80RLceOk6L3vpBevJJjU0amDv+wJTPpWbNdhTWtKkuazw+9+GzXKTPOSZ0/5CVe5tGdRlZqpe4Nnfc+qzUNMKa7TX6q6JtVR3WqC/jdV/Pd7W8/1VS48ahHynv2vLAA6XevaV27bSu9xl6suszejfxNC3jAG1p3lY3NnxeIJ3bOKz4fs/7+p7Q57O+4zH6x1/Xa+lShZ0xt90WPpwTTpAefTR8Wd5/X5lnnaOHu7+i07r+qg3LN+34Yi1dquwJ72vB3a+GzY2tW7V9e2gwJCdH1kVr1+Y//Cjne5mVre3p2yWFzzIpSRo/PvJcekb4Ao4erQeHp+e+1RdGF5GwBVZOkydL743PCjvwd7dnPTNTys7W0qXhoIVRo8KkjjoqfD8LGj1a+tvfymb/hwe6i1vjx4eVQ96uDCnsBP7ww3B/2rTQm7J9e/5x/vtf6fzzMlWjUrqaNEjP3X/w6qvS+vXSpZeGFdAzz+zIySOPlGrVys59XLOmdOWVUv362eraNWRfzsrlnLOz9OUHm7R6VbaqVJEuvDAEQvXq2Wp+YLrq1dyqK09PFUiNGm6XJk5USvV1AumG1uP00eVvqGnDdFWvmqkzT9mspIRM9agyQxe1/VqtaywN82edLmgxSYc2WKFzj1+lT9/8TRo5UrP73KhHmj2s7X1P16Ba4/JlfeXEDIF0ft33lN3yID161KuqUXlrWFk1/0Ut7WeB1LrSIi3gYI1POE2Dar+trsmzdCyf6V5u0rucqsOTvs+d5tAK/9KsZn10e/I/tJ4aupH7BNKV/Evbm/9OE2/6OHfc8xp8FNbEycnSkCHSJZco8/iT9OjBI9Qq4Sc1YYlmtT1byZauJLapEulqXWmRaiakaRh3ah011d5m6rB6i9S2ymJ1ZqqyL70sHGX19dfSQw9p3eEn6zX6K71OI6Uf+3sNavPf3BXnh5wgNWqkTWeerxdrXqkpDU7R9iN6avI5/9T65/8TPvD69fVBhxtUvWpm6EqsuE2P35uW+x4md7pCuv12aehQzW50oipY2Oc0asTGUMe0abnfs+2bt+qqM1L11fM/hh1fn34aVip7yQPduV2YOnXH0ZuXX77z81u3hh3JrVqFfbDr14eu90WLQkAnJ4fzAmbODONed53Up0/uPuHcvx9+CDtAzz5b+t3vpEceCfkD4ehQKeycvu66HS29//0v7B5o1kw66STlOyJo3oRFOun47apZMzSea9cO0zr11B37NX7/+0jgDg1bTg88ELaavvgif2syZ3dA06ZSy8YZeqzZP1Q5IT3fiuukk6TDOuwY1qhRtkaPytJlpy1VgmWpSmJ4LqXWBoHUoU1YcZxW7ROdy8uqxW+6vtKI8H4bLdGw9m9qKxW0oUZj9a31ZRhe/ydVStym6ombZGTp6/4Pq2/zWTql3rfqV+tzgZRcMWzVPJ50jZ6pca1AOoLJeoLLNZI/aRDPq6ptDvNu+oMG1pkgkG6u87Ta1fyf6lXbovMPmKi6tmNLqHriJoHUiWn6jVr6ps0FqsImdeQHfcgJqkh4Lwfxk+qzUsdX/a9m0EHvJ5yq7jXnq27ibzqaSarCJt3BHRrKQzqw8jr9+8gn9UzlqwRSE5ZoI+GDyb72ur3+vnqgO7cb770XDgfduLHw51evLvq5ojazN23asSn+9NOFj5OVFXpMBg3a45J3kpEh3X132P9x+OHS1VeH//CUlPw7y3cl73v57ruwC+Djj/P3UMyYEfrCc4atWxdWBEceGbr769WTjjkmrNz+9a8dK7RLBmzUpo3Zuu46qWfPMKxtq0zVqpWtxMSwpSVJTzwRnjvrrJ3rmz497L7o1k36LXWzsjO2auRIqXHDHeda1KmVpUGDQgM6Z9jw4eH18+aF/TUpKWH6n34aTj67+GLpH/dmqmKFLNWtsVVm2WrZZKtW/O0paf583XjBMoH04lXf6KFh6/OtqM2kV16Rlk2cqSNSlsgsW0kJmWrKYlVhkw6ovE4tG26UWbZOarNY3Vuv16PD03Z+c8Xkge5cOfbLL2F/ZUlZvTp0L2Vnh7Aqi6NmMjJ2rAw2bcp/4tZDD4VDR7/5Jv9r3nxTatMmHEL67bc7hmdnh5OXly8v/vy3b5eWLg37bvLuc3n00bDVk3dFtat+7gkTpNNOCyvGpXkOWMrICDuqs7LCexs1Kqy8vvpq5x23aWlhF0HqrN9Up07onvvkk3BSNoSV0csvF/+9FbSrQPfL5zrnSl16ev4rle4vvvoKvvkGrr8esrLCr1M2aLBv09zV5XP94lzOuVK3P4Y5hJ83OProcD8xcd/DfHf8eujOORcnPNCdcy5OeKA751yc8EB3zrk44YHunHNxwgPdOefihAe6c87FCQ9055yLE1E7U9TMVgNL9vLl9YA1JVhOSSqvtXlde6a81gXltzava8/sbV3NJNUv7ImoBfq+MLMpRZ36Gm3ltTava8+U17qg/Nbmde2Z0qjLu1yccy5OeKA751yciNVAHxntAnahvNbmde2Z8loXlN/avK49U+J1xWQfunPOuZ3FagvdOedcAR7ozjkXJ2Iu0M3sZDNbYGYLzezmKNbRxMw+M7O5ZjbHzP4SGX6nmS01s+mRv1OjUNtiM5sVmf+UyLA6ZvaRmf0Uua0dhbpa51ku081sg5kNicYyM7NRZrbKzGbnGVboMrJgROQ7N9PMupRxXQ+Y2fzIvN8ys1qR4c3NLD3PcnuqjOsq8nMzs1siy2uBmf2+tOraRW2v5qlrsZlNjwwvy2VWVEaU3vesqN+mK49/QCLwM9ASqAjMAA6JUi0HAl0i96sDPwKHAHcC10d5OS0G6hUY9g/g5sj9m4H7y8FnuQJoFo1lBhwDdAFm724ZAacC7wMGHA58W8Z1nQQkRe7fn6eu5nnHi8LyKvRzi/wfzAAqAS0i/7OJZVlbgecfAoZFYZkVlRGl9j2LtRZ6d2ChpEWStgFjgX7RKETScknTIvc3AvOAxtGopZj6Af+O3P83cHoUawE4HvhZ0t6eLbxPJE0CfiswuKhl1A94QcE3QC0zO7Cs6pL0oaTMyMNvgJTSmPee1rUL/YCxkrZK+gVYSPjfLfPazMyAc4BXSmv+RdlFRpTa9yzWAr0x8Guex6mUgxA1s+ZAZ+DbyKCrIptMo6LRtQEI+NDMpprZpZFhDSUtj9xfATSMQl15nUv+f7JoLzMoehmVp+/dRYRWXI4WZvaDmX1hZj2jUE9hn1t5Wl49gZWSfsozrMyXWYGMKLXvWawFerljZtWAN4EhkjYATwIHAZ2A5YTNvbJ2tKQuwCnAlWZ2TN4nFbbvona8qplVBE4DXo8MKg/LLJ9oL6PCmNltQCYwJjJoOdBUUmfgWuBlM6tRhiWVu8+tEAPI33Ao82VWSEbkKunvWawF+lKgSZ7HKZFhUWFmFQgf1BhJ/wGQtFJSlqRs4BlKcVOzKJKWRm5XAW9FaliZs/kWuV1V1nXlcQowTdJKKB/LLKKoZRT1752ZDQb6AgMjIUCkS2Nt5P5UQl91q7KqaRefW9SXF4CZJQFnAq/mDCvrZVZYRlCK37NYC/TvgYPNrEWklXcu8E40Con0zT0HzJP0cJ7hefu8zgBmF3xtKddV1cyq59wn7FCbTVhOgyKjDQLeLsu6CsjXaor2MsujqGX0DnBB5CiEw4G0PJvMpc7MTgZuBE6TtCXP8Ppmlhi53xI4GFhUhnUV9bm9A5xrZpXMrEWkru/Kqq48TgDmS0rNGVCWy6yojKA0v2dlsbe3JP8Ie4J/JKxZb4tiHUcTNpVmAtMjf6cCLwKzIsPfAQ4s47paEo4wmAHMyVlGQF3gE+An4GOgTpSWW1VgLVAzz7AyX2aEFcpyYDuhr/LiopYR4aiDxyPfuVlAtzKuayGhbzXne/ZUZNyzIp/xdGAa8IcyrqvIzw24LbK8FgCnlPVnGRk+Gri8wLhlucyKyohS+575qf/OORcnYq3LxTnnXBE80J1zLk54oDvnXJzwQHfOuTjhge6cc3HCA9055+KEB7pzzsWJ/wcSKo54O3uAkQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-ugKF141J91"
      },
      "source": [
        "model.save('model_ML.h5')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oDItql3Q6qq",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "cd54ea50-8105-4f79-b648-b7820ff0e61b"
      },
      "source": [
        "#Kode buat uji coba modelnya pake input foto interaktif\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  path = fn\n",
        "  img = image.load_img(path, grayscale=True, target_size=(28, 28))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  index_max = np.argmax(classes)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(fn)\n",
        "  print(classes)\n",
        "  print(index_max)\n",
        "  if index_max == 0:\n",
        "    print(\"Huruf A\")\n",
        "  elif index_max == 1:\n",
        "    print(\"Huruf B\")\n",
        "  elif index_max == 2:\n",
        "    print(\"Huruf C\")\n",
        "  elif index_max == 3:\n",
        "    print(\"Huruf D\")\n",
        "  elif index_max == 4:\n",
        "    print(\"Huruf E\")\n",
        "  elif index_max == 5:\n",
        "    print(\"Huruf F\")\n",
        "  elif index_max == 6:\n",
        "    print(\"Huruf G\")\n",
        "  elif index_max == 7:\n",
        "    print(\"Huruf H\")\n",
        "  elif index_max == 8:\n",
        "    print(\"Huruf I\")\n",
        "  elif index_max == 9:\n",
        "    print(\"Huruf J\")\n",
        "  elif index_max == 10:\n",
        "    print(\"Huruf K\")\n",
        "  elif index_max == 11:\n",
        "    print(\"Huruf L\")\n",
        "  elif index_max == 12:\n",
        "    print(\"Huruf M\")\n",
        "  elif index_max == 13:\n",
        "    print(\"Huruf N\")\n",
        "  elif index_max == 14:\n",
        "    print(\"Huruf O\")\n",
        "  elif index_max == 15:\n",
        "    print(\"Huruf P\")\n",
        "  elif index_max == 16:\n",
        "    print(\"Huruf Q\")\n",
        "  elif index_max == 17:\n",
        "    print(\"Huruf R\")\n",
        "  elif index_max == 18:\n",
        "    print(\"Huruf S\")\n",
        "  elif index_max == 19:\n",
        "    print(\"Huruf T\")\n",
        "  elif index_max == 20:\n",
        "    print(\"Huruf U\")\n",
        "  elif index_max == 21:\n",
        "    print(\"Huruf V\")\n",
        "  elif index_max == 22:\n",
        "    print(\"Huruf W\")\n",
        "  elif index_max == 23:\n",
        "    print(\"Huruf X\")\n",
        "  elif index_max == 24:\n",
        "    print(\"Huruf Y\")\n",
        "  elif index_max == 25:\n",
        "    print(\"Huruf Z\")\n",
        "  print(\"\\n\")\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b17bb8e2-a09a-4527-8a68-042d34110632\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b17bb8e2-a09a-4527-8a68-042d34110632\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 1.jpg to 1.jpg\n",
            "\n",
            "\n",
            "1.jpg\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]]\n",
            "16\n",
            "Huruf Q\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fq2zmH_2Ysi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}